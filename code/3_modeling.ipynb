{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone Project - Wine Recommender System <br> [Part 3 of 3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4oQlBkKIzq5F"
   },
   "source": [
    "## Contents:\n",
    "- [Modeling](##Modeling)\n",
    "- [Hyperparameter Tuning](##Hyperparameter-Tuning)\n",
    "- [Conclusion](##Conclusion)\n",
    "- [Limitations](##Limitations)\n",
    "- [Recommendations](##Recommendations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gDgLbO48JwJX"
   },
   "source": [
    "---\n",
    "## Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from surprise import NormalPredictor, BaselineOnly, KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline, SVD, NMF, CoClustering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iaRZZCcTKq5s"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/wine_reviews_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique ID to each wine\n",
    "df['wine_id'] = df.index\n",
    "\n",
    "# Assign a unique ID to each taster\n",
    "taster_ids = df['taster_name'].drop_duplicates().reset_index(drop=True)\n",
    "df['user_id'] = df['taster_name'].map(lambda taster: taster_ids[taster_ids == taster].index[0])\n",
    "\n",
    "# Save the updated DataFrame as a pickle file\n",
    "df.to_pickle('../data/wine_reviews_clean.pkl')\n",
    "\n",
    "# Convert the dataframe to a user preferences format\n",
    "user_prefs = df[['user_id', 'wine_id', 'points']]\n",
    "\n",
    "# Save user preferences dataframe\n",
    "user_prefs[['user_id', 'wine_id', 'points']].to_csv(\"../data/user_prefs.csv\", index=False)\n",
    "\n",
    "# Load data\n",
    "reader = Reader(line_format='user item rating', sep=',', rating_scale=(90, 100), skip_lines=1)\n",
    "data = Dataset.load_from_file(\"../data/user_prefs.csv\", reader=reader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Surprise library may be used for building and evaluating collaborative filtering-based recommendation systems. It provides several built-in algorithms to experiment with and evaluate different recommendation strategies. The algorithms in this list include:\n",
    "\n",
    "`Normal Predictor`: Predicts a random rating based on the distribution of the training set, which is assumed to be normal. It is mostly used for a baseline to compare with more advanced algorithms\n",
    "\n",
    "`Baseline Predictor`: Predicts ratings based on the overall mean rating, user biases, and item biases. It's a basic yet effective model for handling user and item biases in collaborative filtering\n",
    "\n",
    "`KNN Basic`: A collaborative filtering algorithm based on k-Nearest Neighbors, which uses the similarities between users or items to make recommendations. This is the most basic version of the KNN algorithm\n",
    "\n",
    "`KNN with Means`: An extension of the KNN Basic algorithm, which takes into account the mean ratings of each user or item while computing similarities\n",
    "\n",
    "`KNN with Z-score`: Another extension of the KNN Basic algorithm, which normalizes the ratings using the z-score normalization method while computing similarities\n",
    "\n",
    "`KNN Baseline`: A more advanced version of the KNN Basic algorithm that considers both user and item biases while computing similarities\n",
    "\n",
    "`SVD`: A matrix factorization technique that is particularly effective for sparse datasets\n",
    "\n",
    "`Non-negative Matrix Factorization (NMF)`: Enforces non-negativity constraints on the factor matrices. This can be useful for certain types of data, such as when the ratings are only positive\n",
    "\n",
    "`Co-Clustering`: A collaborative filtering algorithm that clusters both users and items simultaneously, allowing for the simultaneous grouping of users and items to discover latent structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the algorithms\n",
    "algorithms = [\n",
    "    ('Normal Predictor', NormalPredictor()),\n",
    "    ('Baseline Predictor', BaselineOnly()),\n",
    "    ('KNN Basic', KNNBasic()),\n",
    "    ('KNN with Means', KNNWithMeans()),\n",
    "    ('KNN with Z-score', KNNWithZScore()),\n",
    "    ('KNN Baseline', KNNBaseline()),\n",
    "    ('SVD', SVD()),\n",
    "    ('Non-negative Matrix Factorization', NMF()),\n",
    "    ('Co-Clustering', CoClustering()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=random.seed(42))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threshold value determines the benchmark for wines to be considered relevant. \n",
    "\n",
    "We will set our threshold to be 91 points, which is the median of our dataset. A low threshold means that wines with lower ratings will be considered relevant, while a high threshold requires wines to have higher ratings to be considered relevant. \n",
    "\n",
    "When the threshold is low, precision might be high because many wines are considered relevant, but recall might be lower because fewer relevant wines are included in the top k recommendations. \n",
    "\n",
    "When the threshold is high, precision might be lower because only a few wines meet the high rating requirement, but recall might be higher because more of the relevant wines are included in the top k recommendations.\n",
    "- `Precision@k` : Proportion of relevant wines among the top k recommendations, i.e. relevance of recommended wines\n",
    "- `Recall@k` : Proportion of relevant wines among the top k recommendations out of all the relevant wines, i.e. coverage of relevant wines\n",
    "\n",
    "A high precision means that the recommender is providing mostly relevant recommendations, which can be beneficial if users prefer a small, highly curated set of options.\n",
    "\n",
    "A high recall means that the recommender is capturing most of the relevant items, which is useful if users want to ensure they are not missing out on any good options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Precision@k and Recall@k\n",
    "def precision_recall_at_k(predictions, k=10, threshold=91):\n",
    "    user_est_true = dict()\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        if uid not in user_est_true:\n",
    "            user_est_true[uid] = []\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now evaluate the performance of the above-mentioned algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Normal Predictor...\n",
      "Evaluating Baseline Predictor...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating KNN Basic...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating KNN with Means...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating KNN with Z-score...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating KNN Baseline...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating SVD...\n",
      "Evaluating Non-negative Matrix Factorization...\n",
      "Evaluating Co-Clustering...\n"
     ]
    }
   ],
   "source": [
    "def evaluate_algorithms(algorithms, data, k_fold):\n",
    "    results = []\n",
    "    for name, algo in algorithms:\n",
    "        print(f\"Evaluating {name}...\")\n",
    "        algo_results = cross_validate(algo, data, measures=['RMSE'], cv=k_fold, verbose=False)\n",
    "        rmse = algo_results['test_rmse'].mean()\n",
    "\n",
    "        # Precision and Recall\n",
    "        precisions_list = []\n",
    "        recalls_list = []\n",
    "        for trainset, testset in k_fold.split(data):\n",
    "            algo.fit(trainset)\n",
    "            predictions = algo.test(testset)\n",
    "            precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=91)\n",
    "\n",
    "            precisions_list.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "            recalls_list.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "\n",
    "        precision = sum(precisions_list) / len(precisions_list)\n",
    "        recall = sum(recalls_list) / len(recalls_list)\n",
    "\n",
    "        results.append({\n",
    "            'Algorithm': name,\n",
    "            'RMSE': rmse,\n",
    "            'Precision@k': precision,\n",
    "            'Recall@k': recall,\n",
    "        })\n",
    "    return results\n",
    "# Call the evaluate_algorithms function and store the results\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=random.seed(42))\n",
    "results = evaluate_algorithms(algorithms, data, k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our case, we will prioritise Precision@k as we will be seeking a smaller and more refined set of recommendations and are not concerned about potentially missing some relevant options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the results DataFrame: Index(['Algorithm', 'RMSE', 'Precision@k', 'Recall@k'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal Predictor</td>\n",
       "      <td>2.175761</td>\n",
       "      <td>0.570322</td>\n",
       "      <td>0.163188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline Predictor</td>\n",
       "      <td>1.614244</td>\n",
       "      <td>0.723860</td>\n",
       "      <td>0.096348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Basic</td>\n",
       "      <td>1.632087</td>\n",
       "      <td>0.599323</td>\n",
       "      <td>0.198327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN with Means</td>\n",
       "      <td>1.632039</td>\n",
       "      <td>0.574854</td>\n",
       "      <td>0.192204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN with Z-score</td>\n",
       "      <td>1.632056</td>\n",
       "      <td>0.589415</td>\n",
       "      <td>0.198940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN Baseline</td>\n",
       "      <td>1.614310</td>\n",
       "      <td>0.721053</td>\n",
       "      <td>0.092490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVD</td>\n",
       "      <td>1.614688</td>\n",
       "      <td>0.737544</td>\n",
       "      <td>0.066276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Non-negative Matrix Factorization</td>\n",
       "      <td>1.632061</td>\n",
       "      <td>0.597368</td>\n",
       "      <td>0.191382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Co-Clustering</td>\n",
       "      <td>1.632067</td>\n",
       "      <td>0.573216</td>\n",
       "      <td>0.185433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Algorithm      RMSE  Precision@k  Recall@k\n",
       "0                   Normal Predictor  2.175761     0.570322  0.163188\n",
       "1                 Baseline Predictor  1.614244     0.723860  0.096348\n",
       "2                          KNN Basic  1.632087     0.599323  0.198327\n",
       "3                     KNN with Means  1.632039     0.574854  0.192204\n",
       "4                   KNN with Z-score  1.632056     0.589415  0.198940\n",
       "5                       KNN Baseline  1.614310     0.721053  0.092490\n",
       "6                                SVD  1.614688     0.737544  0.066276\n",
       "7  Non-negative Matrix Factorization  1.632061     0.597368  0.191382\n",
       "8                      Co-Clustering  1.632067     0.573216  0.185433"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "print(\"Columns in the results DataFrame:\", results.columns)\n",
    "results = results[['Algorithm', 'RMSE', 'Precision@k', 'Recall@k']]\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 76.0% of the top 10 recommended wines are relevant to the user's preferences and the system is able to recommend about 6.9% of all relevant wines within the top 10 recommendations.\n",
    "\n",
    "In other words, even though the recommender might not be capturing all relevant wines within the top 10 recommendations, it is providing accurate top recommendations to the user, which is our priority."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose the SVD algorithm for tuning as it has the one of the **lowest RMSE** scores and the **highest Precision@k** score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Hyperparameter Tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for SVD\n",
    "param_grid = {\n",
    "    'n_factors': [100],                 # [50, 100, 150] \n",
    "    'n_epochs': [30],                   # [20, 30, 40]  \n",
    "    'lr_all': [0.002],                  # [0.001, 0.002, 0.005] \n",
    "    'reg_all': [0.005],                 # [0.005, 0.05, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score of tuned SVD model is 1.614644\n",
      "Best parameters of tuned SVD model are {'n_factors': 100, 'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and fit tuned SVD model using GridSearchCV\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5, n_jobs=-1)\n",
    "grid_search.fit(data)\n",
    "\n",
    "print(f'Best RMSE score of tuned SVD model is {round(grid_search.best_score[\"rmse\"],6)}')\n",
    "print(f'Best parameters of tuned SVD model are {grid_search.best_params[\"rmse\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVD model with the best hyperparameters\n",
    "tuned_svd = SVD(\n",
    "    n_factors=grid_search.best_params[\"rmse\"][\"n_factors\"],\n",
    "    n_epochs=grid_search.best_params[\"rmse\"][\"n_epochs\"],\n",
    "    lr_all=grid_search.best_params[\"rmse\"][\"lr_all\"],\n",
    "    reg_all=grid_search.best_params[\"rmse\"][\"reg_all\"],\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVD model:\n",
      "Precision@k: 0.7268\n",
      "Recall@k: 0.0876\n"
     ]
    }
   ],
   "source": [
    "# Precision and Recall\n",
    "k_fold = KFold(n_splits=5, random_state=42)\n",
    "precisions_list = []\n",
    "recalls_list = []\n",
    "\n",
    "for trainset, testset in k_fold.split(data):\n",
    "    tuned_svd.fit(trainset)\n",
    "    predictions = tuned_svd.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=91)\n",
    "\n",
    "    precisions_list.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    recalls_list.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "\n",
    "precision = sum(precisions_list) / len(precisions_list)\n",
    "recall = sum(recalls_list) / len(recalls_list)\n",
    "\n",
    "print(f\"Tuned SVD model:\")\n",
    "print(f\"Precision@k: {precision:.4f}\")\n",
    "print(f\"Recall@k: {recall:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Precision@k value decreased from 76% to 72.7% and the Recall@k value increased from 6.9% to 8.8%. Given these results, it's hard to determine if there's overfitting without further analysis. The decrease in Precision@k and the slight improvement in RMSE and Recall@k might suggest that the model has become more general, potentially reducing overfitting. However, it's essential to analyze other factors like training and validation errors, learning curves, and additional metrics to conclude whether overfitting is present.\n",
    "\n",
    "Overall, the results indicate that hyperparameter tuning had a mixed effect on the wine recommender system's performance. Since Precision@k is the most important metric for our case, we will not use the tuned model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varying k-values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will vary the value of k for our default SVD model to get its corresponding precision and recall values. We will plot the precision and recall values for different values of k and see how they vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABg/UlEQVR4nO3deVhUZf8G8Hv2YdhUQEBFIM1911TwdRdcc6vXrVxSezNsUVpezbefS5ZWpliJablki1lpVoYpppJmixkupaXlgguooMg+6/P7Y2BkGEBmBAaP9+e65po5Z86c88zXg9w85znnyIQQAkREREQSIXd3A4iIiIgqE8MNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww3dtvXr10Mmk9keSqUSDRo0wCOPPIKLFy9We3smTZqEsLAwpz5z9uxZyGQyrF+/vkraVFOEhYVh0qRJt1yu+L+nTCaDj48PIiMjsXHjxqpvZAXMmzcPMpnMbl6vXr3Qq1evSttGQkIC5s2bV2nrc4fKrokzwsLCMGTIELdsuyRX/k+gO5vS3Q0g6Vi3bh2aNWuG/Px8fP/991i0aBGSkpJw7NgxeHp6Vls7XnzxRTz99NNOfSY4OBg//vgjGjVqVEWtuvM8+OCDeOaZZyCEwJkzZ/DKK69g3LhxEEJg3Lhx7m5elUtISMCKFSvu6IATHx/v7iYQuQXDDVWaVq1aoVOnTgCA3r17w2w246WXXsLWrVvx0EMPlfqZvLw86HS6Sm2HKwFFo9Gga9euldqOO11gYKCtJhEREejWrRvCwsKwatWquyLc1ETO/ry0aNGiCltDVHPxsBRVmaJfjOfOnQNg7Rr28vLCsWPHEB0dDW9vb/Tt2xcAYDAYsHDhQjRr1gwajQYBAQF45JFHcPXqVYf1fvzxx4iIiICXlxe8vLzQrl07rFmzxvZ+aV3Qn332Gbp06QJfX1/odDrcc889mDx5su39sg5L7d+/H3379oW3tzd0Oh0iIyPxzTff2C1TdFhuz549ePzxx+Hv7w8/Pz+MHDkSly5dumWdfv31V4wZMwZhYWHw8PBAWFgYxo4da6ubK9sxGo14/vnnERQUBJ1Oh3/961/45ZdfbtmW8oSGhiIgIACXL1+2m5+VlYVnn30W4eHhUKvVqF+/PmbMmIHc3Fy75SwWC9566y20a9cOHh4eqFWrFrp27YqvvvrKtsymTZsQHR2N4OBgeHh4oHnz5pg1a5bDum5HRbYxadIkrFixAoD9IbqzZ8+Wus4ZM2bA09MTWVlZDu+NHj0agYGBMBqNTn3Hsn5eXnrpJSiVSpw/f95hW5MnT4afnx8KCgoAOB6WKtrPlyxZgqVLlyI8PBxeXl6IiIjATz/95LC+d999F02aNIFGo0GLFi3w8ccf39Yhnvj4eCiVSsydO7fMZYYPH47Q0FBYLBaH97p06YIOHTrYplesWIEePXqgbt268PT0ROvWrfHaa6/Zal2W8g5Dy2Qyh966U6dOYdy4cahbty40Gg2aN29u2z+KWCwWLFy4EE2bNrXt323atMHy5cvLbQtVDfbcUJX5+++/AQABAQG2eQaDAUOHDsVjjz2GWbNmwWQywWKxYNiwYdi3bx+ef/55REZG4ty5c5g7dy569eqFX3/9FR4eHgCA//u//8NLL72EkSNH4plnnoGvry9+//13hyBQ3I8//ojRo0dj9OjRmDdvHrRaLc6dO4fdu3eX2/6kpCRERUWhTZs2WLNmDTQaDeLj43H//fdj48aNGD16tN3yU6dOxeDBg/Hxxx/j/PnzeO655/Dwww/fcjtnz55F06ZNMWbMGNSpUwepqalYuXIl7rvvPhw/fhz+/v5Ob+fRRx/Fhg0b8OyzzyIqKgq///47Ro4ciezs7HLbUp4bN27g2rVrdj1ceXl56NmzJy5cuIAXXngBbdq0wR9//IH/+7//w7Fjx7Br1y7b2JhJkybhww8/xJQpU7BgwQKo1Wr89ttvdoHh1KlTGDRokC0s/Pnnn3j11Vfxyy+/3LKOFVWRbbz44ovIzc3F559/jh9//NH22eDg4FLXOXnyZCxfvhyffvoppk6dapufmZmJL7/8EtOnT4dKpXL6O5b289KuXTu8/PLLWLVqFRYuXGhb9tq1a/jkk0/wxBNPQKvVlluDFStWoFmzZoiLi7N930GDBuHMmTPw9fUFAKxevRqPPfYYHnjgASxbtgw3btzA/PnzodfrK1jpm4QQeO655/Dmm2/ivffeK3fc1+TJkzFs2DDs3r0b/fr1s83/888/8csvv+DNN9+0zfvnn38wbtw4W7A+cuQIXn75Zfz5559Yu3at0+0szfHjxxEZGYmGDRvijTfeQFBQEHbs2IGnnnoK6enptqD22muvYd68efjf//6HHj16wGg04s8//0RmZmaltIOcJIhu07p16wQA8dNPPwmj0Siys7PFtm3bREBAgPD29hZpaWlCCCEmTpwoAIi1a9fafX7jxo0CgNi8ebPd/IMHDwoAIj4+XgghxOnTp4VCoRAPPfRQue2ZOHGiCA0NtU0vWbJEABCZmZllfubMmTMCgFi3bp1tXteuXUXdunVFdna2bZ7JZBKtWrUSDRo0EBaLxe77x8TE2K3ztddeEwBEampque0tyWQyiZycHOHp6SmWL19um1/R7Zw4cUIAEDNnzrRb7qOPPhIAxMSJE2/ZhqLtGI1GYTAYxMmTJ8XQoUOFt7e3+PXXX23LLVq0SMjlcnHw4EG7z3/++ecCgEhISBBCCPH9998LAGLOnDkVroPFYhFGo1EkJSUJAOLIkSO29+bOnStK/vfVs2dP0bNnzwqv/1bbmD59usM2ytOhQwcRGRlpNy8+Pl4AEMeOHXN6+2X9vBS9V7duXaHX623zXn31VSGXy8WZM2ds80rWpGg/b926tTCZTLb5v/zyiwAgNm7cKIQQwmw2i6CgINGlSxe77Z47d06oVCq7n6+yhIaGisGDB4u8vDzxwAMPCF9fX7Fr165bfs5oNIrAwEAxbtw4u/nPP/+8UKvVIj09vdTPmc1mYTQaxYYNG4RCoRDXrl2zvVfy/4TSft6LABBz5861Tffv3180aNBA3Lhxw265J554Qmi1Wtt2hgwZItq1a3fL70fVg4elqNJ07doVKpUK3t7eGDJkCIKCgrB9+3YEBgbaLffAAw/YTW/btg21atXC/fffD5PJZHu0a9cOQUFB2Lt3LwAgMTERZrMZ06dPd6pd9913HwBg1KhR+PTTTyt0Bldubi5+/vlnPPjgg/Dy8rLNVygUGD9+PC5cuIC//vrL7jNDhw61m27Tpg0AlNurBAA5OTn473//i8aNG0OpVEKpVMLLywu5ubk4ceKEw/K32s6ePXsAwGGc06hRo6BUVryzNj4+HiqVCmq1Gk2aNMH27duxceNGdOzY0bbMtm3b0KpVK7Rr187u365///6QyWS2f7vt27cDwC3/7U6fPo1x48YhKCgICoUCKpUKPXv2BIBSa+GKqtrGI488ggMHDtjtF+vWrcN9992HVq1aubz9kj8vAPD000/jypUr+OyzzwBYD4msXLkSgwcPrtAho8GDB0OhUNimS+5Df/31F9LS0jBq1Ci7zzVs2BDdunW75fqLZGRkoE+fPvjll19sh3hvRalU4uGHH8aWLVtw48YNAIDZbMYHH3yAYcOGwc/Pz7ZscnIyhg4dCj8/P1stJ0yYALPZjJMnT1a4nWUpKCjAd999hxEjRkCn09nt44MGDUJBQYHtcF7nzp1x5MgRxMTEYMeOHaUeoqTqw3BDlWbDhg04ePAgkpOTcenSJRw9etThP0KdTgcfHx+7eZcvX0ZmZibUajVUKpXdIy0tDenp6QBgG3/ToEEDp9rVo0cPbN26FSaTCRMmTECDBg3QqlWrck9rvn79OoQQpR6GqFevHgDrf9zFFf9PF7AOUgaA/Pz8cts3btw4vP3225g6dSp27NiBX375BQcPHkRAQECpn73VdoraFRQUZLecUql0+Gx5Ro0ahYMHD+LAgQNYtWoVvL29MWbMGJw6dcq2zOXLl3H06FGHfzdvb28IIez+7RQKhUObisvJyUH37t3x888/Y+HChdi7dy8OHjyILVu22H2/21GV23jooYeg0Whs4ziOHz+OgwcP4pFHHnF5+6X9vABA+/bt0b17d9u4j23btuHs2bN44oknKtTWiu5DJf8wKWteWU6ePImff/4ZAwcOtAt4tzJ58mQUFBTgk08+AQDs2LEDqampdrVMSUlB9+7dcfHiRSxfvhz79u3DwYMHbTWpjP0lIyMDJpMJb731lsM+PmjQIACw7eOzZ8/GkiVL8NNPP2HgwIHw8/ND37598euvv952O8h5HHNDlaZ58+a2s6XKUvLaJABsA2O//fbbUj/j7e0N4ObYnQsXLiAkJMSptg0bNgzDhg2DXq/HTz/9hEWLFmHcuHEICwtDRESEw/K1a9eGXC5Hamqqw3tFg3dLjoVxxY0bN7Bt2zbMnTsXs2bNss3X6/W4du2aS+ss+sWVlpaG+vXr2+abTCaHQFaegIAA279nREQEmjdvjp49e2LmzJnYtm0bAGsNPDw8yhzfUFSjgIAAmM1mpKWllTluZffu3bh06RL27t1r68kAUKljFqpyG7Vr18awYcOwYcMGLFy4EOvWrYNWq8XYsWNd3n5pPy9FnnrqKfz73//Gb7/9hrfffhtNmjRBVFTUbX8P4OY+VHLwOGDdryoqIiIC//73vzFlyhQAwMqVKyGX3/pv6hYtWqBz585Yt24dHnvsMaxbtw716tVDdHS0bZmtW7ciNzcXW7ZsQWhoqG3+4cOHb7n+ojFJJccPlfz5qF27tq23tqxex/DwcADWPx5iY2MRGxuLzMxM7Nq1Cy+88AL69++P8+fPV/pZoVQ+9tyQ2w0ZMgQZGRkwm83o1KmTw6Np06YAgOjoaCgUCqxcudLlbWk0GvTs2ROvvvoqAGu3dmk8PT3RpUsXbNmyxe4vQIvFgg8//BANGjRAkyZNXG5HEZlMBiGE7S/nIu+99x7MZrNL6yw6O+ajjz6ym//pp5/CZDK5tE4A6N69OyZMmIBvvvnGNsh2yJAh+Oeff+Dn51fqv13RIZKBAwcCQLn/dkW/yEvWYtWqVS63+Xa2UdGet+IeeeQRXLp0CQkJCfjwww8xYsQI1KpVy6Xt38qIESPQsGFDPPPMM9i1axdiYmLKDUPOaNq0KYKCgvDpp5/azU9JScGBAwecWtfEiRPxySefYN26dbZDRhXxyCOP4Oeff8b+/fvx9ddfY+LEiXaH0kqrpRAC77777i3XHRgYCK1Wi6NHj9rN//LLL+2mdTodevfujeTkZLRp06bUfby03tBatWrhwQcfxPTp03Ht2rUyz7KjqsOeG3K7MWPG4KOPPsKgQYPw9NNPo3PnzlCpVLhw4QL27NmDYcOGYcSIEQgLC8MLL7yAl156Cfn5+Rg7dix8fX1x/PhxpKenY/78+aWu///+7/9w4cIF9O3bFw0aNEBmZiaWL19uN9ahNIsWLUJUVBR69+6NZ599Fmq1GvHx8fj999+xcePGSvlF4uPjgx49euD111+Hv78/wsLCkJSUhDVr1tj9UnRG8+bN8fDDDyMuLg4qlQr9+vXD77//jiVLlpR6iMMZL730EjZt2oQXX3wRu3btwowZM7B582b06NEDM2fORJs2bWCxWJCSkoKdO3fimWeeQZcuXdC9e3eMHz8eCxcuxOXLlzFkyBBoNBokJydDp9PhySefRGRkJGrXro1p06Zh7ty5UKlU+Oijj3DkyJHbanNxzmyjdevWAIBXX30VAwcOhEKhQJs2baBWq8tcf3R0NBo0aICYmBikpaXZHUZxdvu3olAoMH36dPz3v/+Fp6dnha48XVFyuRzz58/HY489hgcffBCTJ09GZmYm5s+fj+Dg4Ar1vhT34IMPQqfT4cEHH0R+fj42btxYbh0BYOzYsYiNjcXYsWOh1+sdvl9UVBTUajXGjh2L559/HgUFBVi5ciWuX79+y/bIZDI8/PDDWLt2LRo1aoS2bdvil19+wccff+yw7PLly/Gvf/0L3bt3x+OPP46wsDBkZ2fj77//xtdff207w+3++++3XesrICAA586dQ1xcHEJDQ3HvvfdWvFhUOdw7npmkoOgsnpJnzJQ0ceJE4enpWep7RqNRLFmyRLRt21ZotVrh5eUlmjVrJh577DFx6tQpu2U3bNgg7rvvPtty7du3tzvroeSZEdu2bRMDBw4U9evXF2q1WtStW1cMGjRI7Nu3z7ZMWWdP7Nu3T/Tp00d4enoKDw8P0bVrV/H1119X6Pvv2bNHABB79uwpty4XLlwQDzzwgKhdu7bw9vYWAwYMEL///rsIDQ21O7PJme3o9XrxzDPPiLp16wqtViu6du0qfvzxR4d1lgWAmD59eqnvPffccwKASEpKEkIIkZOTI/73v/+Jpk2bCrVaLXx9fUXr1q3FzJkzbWfKCWE9m2XZsmWiVatWtuUiIiLs6nngwAEREREhdDqdCAgIEFOnThW//fabw7/N7ZwtVdFt6PV6MXXqVBEQECBkMpkAYHcmUlleeOEFAUCEhIQIs9ns8vbL+3kpcvbsWQFATJs2rdT3yzpb6vXXX3dYFiXOEhJCiNWrV4vGjRsLtVotmjRpItauXSuGDRsm2rdvX267hLh5tlRxe/bsEV5eXmLAgAEiLy/vlusYN26cACC6detW6vtff/217f+M+vXri+eee05s377d4eeh5P8JQghx48YNMXXqVBEYGCg8PT3F/fffb6tnyTqcOXNGTJ48WdSvX1+oVCoREBAgIiMjxcKFC23LvPHGGyIyMlL4+/sLtVotGjZsKKZMmSLOnj17y+9JlU8mhBDVG6eIiKgyvPXWW3jqqafw+++/o2XLllW+vczMTDRp0gTDhw/H6tWrq3x7RK7iYSkiojtMcnIyzpw5gwULFmDYsGFVEmzS0tLw8ssvo3fv3vDz88O5c+ewbNkyZGdnO33vNqLqxnBDRHSHGTFiBNLS0tC9e3e88847VbINjUaDs2fPIiYmBteuXYNOp0PXrl3xzjvvVEsvEdHt4GEpIiIikhSeCk5ERESSwnBDREREksJwQ0RERJJy1w0otlgsuHTpEry9vSvtap5ERERUtYQQyM7ORr169W55Icm7LtxcunTJ6fsSERERUc1w/vz5W95A+a4LN0U3YTx//rzDpeiNRiN27tyJ6OhoqFQqdzTvjsS6uYZ1cw3r5jzWzDWsm2uqqm5ZWVkICQmx/R4vz10XbooORfn4+JQabnQ6HXx8fLgjO4F1cw3r5hrWzXmsmWtYN9dUdd0qMqSEA4qJiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhSGG6IiIhIUhhuiIiISFIYboiIiEhS7robZ5J0WCwCFiFgEYBFCOu8wmlR7FmIYvNxc7ro2UOlgLdWBbWSWZ+ISAoYbggAkKs3IbvABIPJAr3JDL3JAr3JYps22E3bz8s3GPHXWTkOffMnLACMJgGj2QKD2QKj2QKTWdheG80CJrMFBrMonLbAaLLAIgCzELZQYhECZkvxYCJgsRR7LSq/BlqVHN5aFXy0SuuzhwreWiV8CucVn/YunPZQKSAEYLJYYLYImCzC9mwyW+ymzRZrLYqmDUYTTl+VIfDcdYTX9UGAlwZy+a3vdktEROVjuLnLpefosWTHX/j01/O3GRjkQGpKZTWryshkgFwmg1wGyCADZIDBZAEAFBgtKDDqcTVbX40tUuDDvw8CANRKORrU9kBIbR1C6hQ962zTvh4qyGQMP0REt8Jwc5cymi348KdzWJp4EtkFJgCAUi6DWimHRikvfFbYpkubVzStlAMXzp1Fs3sbQaNWQqWQQ6WQFT7LoVbIoVLKoJQXTitvvqdSWOcr5DLIZbLCZ0BWGECsQUQGubzY68L3bctCBpncPrQUhRi7MFNGMDCZLcgp7LnKKjAiK9+E7AIjsgoKn23TRmQX3Fwuu8CEXL0JSrkMimLfQymXlXgunK+wny8D8Pf5VOTLdUi9UQCDyYLTV3Nx+mpuqe301ijRoI4OIbU9EFJHh/q1POChVkCtkNv9m9heKxQO89VK67+HRilnUCIqZLYIXM8z4FquAek5elzLtb6+mpWPEylynP/+DHw9NYW9ukp4aay9t95aJbw1KnhplVA42etqtgjk6E3I0Vv/H8nRm5BTUOy13gSj2WL9eVUp7P7PLfl/skZV+HOtuvm+WiGv9p5gIQTyDGZcyylAekG1btoBw81d6MDf6Zj39R84eTkHANCyng/mDW2J+8LquLQ+o9GIhITTGBR1L1QqVWU2tVooFXLU0qlRS6eu1u1a63YRgwb1AOQKpGYW4Pz1PJy/llf4nG97Ts/RI1tvwonULJxIzaqU7asUMlswUiuLgufN8KNS2AcilVIOTbF5HioFPNQKeKgU0KkV0KoU0KmV8FDL4aFSwkNtnV+0nE6tgFap4KE3qnJFYSU9R4+MHPvAkpFrwLWcotfW+Zn5Rogye67l2HXx1C236alWwKvwkLaXpigEKWEwWUqEGDNy9EYUGC2V+p1Lo1XJ4aVRQqdWwlOjhJdGAU+NEp5qJTztXt98T6e2tlulkNnaXfSHXnax55wSf+hlFxiRozfZjgDU0SgwYWSVf8UyMdzcRc5fy8MrCSew/fc0AEBtnQrP9W+G0feFOP1XB1UulUKOhn46NPTTlfp+vsGMC9eLhZ5reUjNKoDeaLaNhTKYC5+LjY8qPs9gtv/P1GgWMJrNyDWYq+Mr2mhVcniqlYW/CG7+5Vt8PJP1l0Oxv461N6c1clTJmCuq2Yxmi7U3JVuPjFwD0rP1SM8pelgDzNVs6+truXqX9pHaOhXqeKrh56lBHU81aumUuHQ+Bf7BDZBrMNt6eG8+jNAXHtbONVh/li5nOXdYW62Qw1NjDUaeauu+bg0bSqgVcujNxcY6Fvt5LxobWXwcpN5ksQtp1kPtBgAG54txG6w90+79IWW4uQsUGM14J+kfrNz7D/QmC+QyYHzXUMyMalLtvRXkGg+1AvcGeuPeQG+X1yGEdWC3LfiYrAO6bWGocHB3yUBU/Ln48gVGM/IMZuQbzcgvfM4zmG/OL/FekaL/cDNyb+c/XCVmH9oFT7W1h8j2rFHAQ2X9q1SntvYk2T/f7F3SKhXQFvYsaVWFPUwqRWHXvjQP2xnNFhSYjYX/BubChwX5ttdmFJgsKDCYUWCyTucbLCgwmSEDoFXdPCSiLayVVmn/rFEqoFXdPFyiUSqgUsiQZzAjp8BkCwhFPRnZhYdjcvRGa2+Abfrm43quAdfzjE5/X2tQUcPP62ZgqVM4bXtdOL+2TgWlwv6MSWvv6lkMGtSqzF7pop6Z7GKHrW29G3oTNEq5NawUhvbiAcZTo4BGqXDln7JUQlhPVij6+cw3mJFruNljlFesBynXYLY+F71nuPlensF6woiXVlnKHxsqeGvs/+Ao+QeIEhZs37690r6XKxhuJEwIgW9/T8PCb07gYmY+AKDrPXUwb2hLNAvycXPrqLrJZLLC4/GV959pRVkK/8PNM5iQbzQjV2+2/gLQ2/8yyC4wFuvutv8lUfTaVPgnue2v0tKHKN0WmQx2oUersv4y16oUKOrkFAIQKLzcQOE0YJ2HYvNE4V+wQljXW3zMxM0AUGwshcp+XEXx8RZmi3VMgzU8mmyBMt9gHzTzDCa7oGl9KGD5cVflF6sayWVAHU8N/L3UCPDWwN/L+tr6rIG/d+F7XtbAUjKsVAW1Uo46SmtQcjeZTGYb7+ilcd+vd6PR+SBa2RhuJOrk5WzM++oPHPgnAwBQz1eLOYNbYFDrIEn+RUo1m1wus47PUd9esBJCIDtPj6+370BEj14wWuTINZisf6Hqbwanol/ueYbirwuf9cV6JQp7JvRGM/KMZpgtN4NI0eelw/7nXquS2wLczYe1B8ZDbR/otEoFBG72CBQ/RFJQ4llvtPb0FD0XP0ziVdhb4aVRwquwB8CrWK9GUS9B0XTRw1engr+XBrV1ah5CpwphuJGYG/lGLEs8iQ9+OgezRUCtlGNaz0Z4vGej2/7FQuRuMpk1JHmpgJDaukofwG40W2yhp6DwcEy+4WYQKjDe/GVt/RvBekZe0a9bmcx6FlzR3w+yYpcckMEamoqPjygeEmzzjdbDgHqj43JKhQweKqXDQO3iA7pvvi4c0K1WQCUT+HFfEgb1j4K3TlNth92EEIVjuyzwUHEwOVUfhhuJMFsEPvv1PF7b8ReuFY5l6N8yEP8b3AIhdUofpEpE9oouUeCtvfPO+iuP0WjECQ1QS6eCSlV9f+TIZDKolTJe/ZuqHcPNHe5iZj6+PHwRW367iL+vWE/tblzXC3Pvb4Hu9wa4uXVERETVj+HmDnQjz4iE31OxNfkifj5zzTbfW6PEjKgmmBARClU1DKQjIiKqiRhu7hB6kxl7/ryKrckXsfvPK3bXLOl6Tx2MaF8fA1oFw9dDWt3pREREzmK4qcEsFoGDZ69h6+GL+OZoKrIKb5MAAM2CvDG8fX0MbVsP9Wp5uLGVRERENQvDTQ108nI2vki+iK8OX7JdnwYAgny0GNa+Hoa3q4/mwbxODRERUWkYbmqIAqMZH/50Dlt+u4jjxe4d5K1RYmDrIAxvXx9dwv14jQciIqJbYLipAYQQeObTI/jmWCoA6w0NezWtixHt66NPs7rQVuOpm0RERHc6hpsaYOvhi/jmWCqUchn+7/4WGNq2Hu/5RERE5CKGGze7mJmP//vyDwDA033vxYSIMPc2iIiI6A7Hi6G4kcUi8OynR5BdYEL7hrXweK9G7m4SERHRHY/hxo3W/nAGP57OgIdKgWWj2lXLHWyJiIikzu2/TePj4xEeHg6tVouOHTti3759ZS47adIk643pSjxatmxZjS2uHH+lZeO1HX8BAF4c0gJh/p5ubhEREZE0uDXcbNq0CTNmzMCcOXOQnJyM7t27Y+DAgUhJSSl1+eXLlyM1NdX2OH/+POrUqYN///vf1dzy26M3mTFj02EYTBb0aVYXYzuHuLtJREREkuHWcLN06VJMmTIFU6dORfPmzREXF4eQkBCsXLmy1OV9fX0RFBRke/z666+4fv06HnnkkWpu+e2J23UKJ1KzUMdTjcUPtIZMxmvXEBERVRa3nS1lMBhw6NAhzJo1y25+dHQ0Dhw4UKF1rFmzBv369UNoaGiZy+j1euj1ett0Vpb1AnlGoxFGo9Fu2aLpkvMr06/nruOdpH8AAC8NbY7aWkWVbq86VEfdpIh1cw3r5jzWzDWsm2uqqm7OrM9t4SY9PR1msxmBgYF28wMDA5GWlnbLz6empmL79u34+OOPy11u0aJFmD9/vsP8nTt3QqfTlfqZxMTEW27fFQVm4LUjCgghQ+cAC0xnDyHhbJVsyi2qqm5Sx7q5hnVzHmvmGtbNNZVdt7y8vAov6/br3JQ8JCOEqNBhmvXr16NWrVoYPnx4ucvNnj0bsbGxtumsrCyEhIQgOjoaPj7292cyGo1ITExEVFQUVKrKv7v2C1v/QIb+IurX0uKd/0TCW+v28leKqq6bVLFurmHdnMeauYZ1c01V1a3oyEtFuO23q7+/PxQKhUMvzZUrVxx6c0oSQmDt2rUYP3481Oryr+Sr0Wig0Wgc5qtUqjKLXt57rtr5Rxo+O3QRMhmwdFQ71PGW3p28q6JudwPWzTWsm/NYM9ewbq6p7Lo5sy63DShWq9Xo2LGjQ7dVYmIiIiMjy/1sUlIS/v77b0yZMqUqm1hprmbrMXvLMQDAf3rcgy73+Lm5RURERNLl1uMisbGxGD9+PDp16oSIiAisXr0aKSkpmDZtGgDrIaWLFy9iw4YNdp9bs2YNunTpglatWrmj2U4RQmD2lqPIyDWgWZA3YqOauLtJREREkubWcDN69GhkZGRgwYIFSE1NRatWrZCQkGA7+yk1NdXhmjc3btzA5s2bsXz5cnc02WmbDp7HrhNXoFbIETemHTRK3uGbiIioKrl9RGtMTAxiYmJKfW/9+vUO83x9fZ0aMe1O5zJysWDbcQDAc/2bolmQzy0+QURERLfL7bdfkCqzRSD20yPIM5jRJbwOpvwr3N1NIiIiuisw3FSRd5L+waFz1+GlUeKNUW0hl/MqxERERNWB4aYK/H7xBpYlngQAzB/aEg1ql36xQCIiIqp8DDeVrMBoxsxNh2GyCAxsFYSRHeq7u0lERER3FYabSvbat3/h1JUcBHhr8PII3hSTiIioujHcVKIf/k7H2h/OAABee7AN6niWf/VkIiIiqnwMN5XkRp4Rz352BADwUJeG6N20rptbREREdHdiuKkkZzNyYTRbEOanw5zBzd3dHCIioruW2y/iJxVtQ2phx4weyMg1QKdmWYmIiNyFv4UrkZ+XBn5ejncgJyIiourDw1JEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKW4PN/Hx8QgPD4dWq0XHjh2xb9++cpfX6/WYM2cOQkNDodFo0KhRI6xdu7aaWktEREQ1ndKdG9+0aRNmzJiB+Ph4dOvWDatWrcLAgQNx/PhxNGzYsNTPjBo1CpcvX8aaNWvQuHFjXLlyBSaTqZpbTkRERDWVW8PN0qVLMWXKFEydOhUAEBcXhx07dmDlypVYtGiRw/LffvstkpKScPr0adSpUwcAEBYWVp1NJiIiohrObeHGYDDg0KFDmDVrlt386OhoHDhwoNTPfPXVV+jUqRNee+01fPDBB/D09MTQoUPx0ksvwcPDo9TP6PV66PV623RWVhYAwGg0wmg02i1bNF1yPpWPdXMN6+Ya1s15rJlrWDfXVFXdnFmf28JNeno6zGYzAgMD7eYHBgYiLS2t1M+cPn0a+/fvh1arxRdffIH09HTExMTg2rVrZY67WbRoEebPn+8wf+fOndDpdKV+JjEx0clvQwDr5irWzTWsm/NYM9ewbq6p7Lrl5eVVeFm3HpYCAJlMZjcthHCYV8RisUAmk+Gjjz6Cr68vAOuhrQcffBArVqwotfdm9uzZiI2NtU1nZWUhJCQE0dHR8PHxsVvWaDQiMTERUVFRUKlUt/vV7hqsm2tYN9ewbs5jzVzDurmmqupWdOSlItwWbvz9/aFQKBx6aa5cueLQm1MkODgY9evXtwUbAGjevDmEELhw4QLuvfdeh89oNBpoNBqH+SqVqsyil/celY11cw3r5hrWzXmsmWtYN9dUdt2cWZfbTgVXq9Xo2LGjQ7dVYmIiIiMjS/1Mt27dcOnSJeTk5NjmnTx5EnK5HA0aNKjS9hIREdGdwa3XuYmNjcV7772HtWvX4sSJE5g5cyZSUlIwbdo0ANZDShMmTLAtP27cOPj5+eGRRx7B8ePH8f333+O5557D5MmTyxxQTERERHcXt465GT16NDIyMrBgwQKkpqaiVatWSEhIQGhoKAAgNTUVKSkptuW9vLyQmJiIJ598Ep06dYKfnx9GjRqFhQsXuusrEBERUQ3j9gHFMTExiImJKfW99evXO8xr1qwZR64TERFRmdx++wUiIiKiysRwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLCcENERESSwnBDREREksJwQ0RERJLi9nATHx+P8PBwaLVadOzYEfv27Stz2b1790Imkzk8/vzzz2psMREREdVkbg03mzZtwowZMzBnzhwkJyeje/fuGDhwIFJSUsr93F9//YXU1FTb4957762mFhMREVFN59Zws3TpUkyZMgVTp05F8+bNERcXh5CQEKxcubLcz9WtWxdBQUG2h0KhqKYWExERUU2ndNeGDQYDDh06hFmzZtnNj46OxoEDB8r9bPv27VFQUIAWLVrgf//7H3r37l3msnq9Hnq93jadlZUFADAajTAajXbLFk2XnE/lY91cw7q5hnVzHmvmGtbNNVVVN2fW57Zwk56eDrPZjMDAQLv5gYGBSEtLK/UzwcHBWL16NTp27Ai9Xo8PPvgAffv2xd69e9GjR49SP7No0SLMnz/fYf7OnTuh0+lK/UxiYqKT34YA1s1VrJtrWDfnsWauYd1cU9l1y8vLq/Cybgs3RWQymd20EMJhXpGmTZuiadOmtumIiAicP38eS5YsKTPczJ49G7GxsbbprKwshISEIDo6Gj4+PnbLGo1GJCYmIioqCiqVytWvdNdh3VzDurmGdXMea+Ya1s01VVW3oiMvFeG2cOPv7w+FQuHQS3PlyhWH3pzydO3aFR9++GGZ72s0Gmg0Gof5KpWqzKKX9x6VjXVzDevmGtbNeayZa1g311R23ZxZl9sGFKvVanTs2NGh2yoxMRGRkZEVXk9ycjKCg4Mru3lERER0h3LrYanY2FiMHz8enTp1QkREBFavXo2UlBRMmzYNgPWQ0sWLF7FhwwYAQFxcHMLCwtCyZUsYDAZ8+OGH2Lx5MzZv3uzOr0FEREQ1iFvDzejRo5GRkYEFCxYgNTUVrVq1QkJCAkJDQwEAqampdte8MRgMePbZZ3Hx4kV4eHigZcuW+OabbzBo0CB3fQUiIiKqYdw+oDgmJgYxMTGlvrd+/Xq76eeffx7PP/98NbSKiIiI7lRuv/0CERERUWViuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSWG4ISIiIklhuCEiIiJJYbghIiIiSVG6uwFERHR3M5vNMBqN7m6GA6PRCKVSiYKCApjNZnc3545xO3VTq9WQy2+/34XhhoiI3EIIgbS0NGRmZrq7KaUSQiAoKAjnz5+HTCZzd3PuGLdTN7lcjvDwcKjV6ttqA8MNERG5RVGwqVu3LnQ6XY0LEBaLBTk5OfDy8qqU3oS7hat1s1gsuHTpElJTU9GwYcPb2h8YboiIqNqZzWZbsPHz83N3c0plsVhgMBig1WoZbpxwO3ULCAjApUuXYDKZoFKpXG4D/7WIiKjaFY2x0el0bm4J1SRFh6Nud4wTww0REblNTTsURe5VWfsDww0RERFJikvhxmQyYdeuXVi1ahWys7MBAJcuXUJOTk6lNo6IiIiAsLAwxMXFVfqyVc1dbXF6QPG5c+cwYMAApKSkQK/XIyoqCt7e3njttddQUFCAd955pyraSUREVCNMmjQJ77//PgBAqVQiJCQEI0eOxPz58+Hp6Vkl2zx48GCF1+3Mss4ymUzYsGEDPvnkE/zxxx8wm81o3LgxHnjgAUybNg0eHh5Vsl1nOd1z8/TTT6NTp064fv263ZcYMWIEvvvuu0ptHBERUU00YMAApKam4vTp01i4cCHi4+Px7LPPOixXWRcnDAgIqPDga2eWdcbZs2fRqVMnLF++HCNHjsRnn32GnTt34qmnnsLOnTvRunVr/P3335W+XVc4HW7279+P//3vfw4X2AkNDcXFixcrrWFEREQ1lUajQVBQEEJCQjBu3Dg89NBD2Lp1K+bNm4d27dph7dq1uOeee6DRaCCEwI0bN/Cf//wHdevWhY+PD/r06YMjR47YrfOrr75Cp06doNVq4e/vj5EjR9reK3l4Z968eWjYsCE0Gg3q1auHp556qsxlU1JSMGzYMHh5ecHHxwejRo3C5cuX7dbVrl07fPDBBwgLC4Ovry/GjBljG3YCAFlZWYiOjsbQoUNx+PBhTJs2DZGRkWjTpg1GjRqF7du347///S/69++P/Pz8Muu2bt06+Pr6IjEx0ZWyV5jT4cZisZR6itaFCxfg7e1dKY0iIqK7jxACeQaTWx5CiNtqu4eHh62X5u+//8ann36KzZs34/DhwwCAwYMHIy0tDQkJCTh06BA6dOiAvn374tq1awCAb775BiNHjsTgwYORnJyM7777Dp06dSp1W59//jmWLVuGVatW4dSpU9i6dStat25dZk2HDx+Oa9euISkpCYmJifjnn38wevRou+X++ecfbN26Fdu2bcO2bduQlJSExYsX295/9dVX0aFDByxYsADZ2dmYNGkSgoOD0aFDB6xfvx4tW7bEo48+isjISLz55pultmXJkiV49tlnsWPHDkRFRTlVX2c5PeYmKioKcXFxWL16NQDraVs5OTmYO3cuBg0aVOkNJCKiu0O+0YwW/7fDLds+vqA/dGrXrmv7yy+/4OOPP0bfvn0BAAaDAR988AECAgIAALt378axY8dw5coVaDQaANZf9Fu3bsXnn3+O//znP3j55ZcxZswYzJ8/37betm3blrq9lJQUBAUFoV+/flCpVGjYsCE6d+5c6rK7du3C0aNHcebMGYSEhAAAPvjgA7Rs2RIHDx7EfffdB8DacbF+/XpbJ8X48ePx3Xff4eWXXwYAvP/++/j2228BAM888wxOnDiBzZs3Iy8vD9OnT4derwdgHY80Z84cPP7443btmD17Nt5//33s3bu3zCBWmZzuuVm2bBmSkpLQokULFBQUYNy4cQgLC8PFixfx6quvVkUbiYiIapRt27bBy8sLWq0WERER6NGjB9566y0A1mEaRcEGAA4dOoScnBz4+fnBy8vL9jhz5gz++ecfAMDhw4dt4ehW/v3vfyM/Px/33HMPHn30UXzxxRcwmUylLnvixAmEhITYgg0AtGjRArVq1cKJEyds88LCwuyOvgQHB+PKlSsAgGvXriErKwutWrUCAHz55ZdYunQpIiMj0a9fP7z44ot2n7t+/bpdG9544w2sWrUK+/fvr5ZgA7jQc1OvXj0cPnwYGzduxG+//QaLxYIpU6bgoYcecmmUdHx8PF5//XWkpqaiZcuWiIuLQ/fu3W/5uR9++AE9e/ZEq1atbN1+RER05/JQKXB8QX+3bdsZvXv3xsqVK6FSqVCvXj27WwWUPFPJYrEgODgYe/fudVhPrVq1rNt34vdnSEgI/vrrLyQmJmLXrl2IiYnB66+/jqSkJIdbFgghSr0wXsn5JT8nk8lgsVgAWM+Q0mq1tvcMBoPdd/Ty8rK9PnLkCO655x67dXXv3h3ffPMNPv30U8yaNavC3/N2uNQH5+HhgcmTJ2Py5Mm3tfFNmzZhxowZiI+PR7du3bBq1SoMHDgQx48fR8OGDcv83I0bNzBhwgT07dvXblAUERHduWQymcuHhqqbp6cnGjduXKFlO3TogLS0NCiVSoSFhZW6TJs2bfDdd9/hkUceqdA6PTw8MHToUAwdOhTTp09Hs2bNcOzYMXTo0MFuuRYtWiAlJQXnz5+39d4cP34cN27cQPPmzSu0LX9/fxiNRqSmpiI4OBg9evTA4sWLsWbNGhQUFNgGLx8+fBhz5sxBfHy83ec7d+6MJ598Ev3794dCocBzzz1Xoe3eDqf3og0bNpT7/oQJEyq8rqVLl2LKlCmYOnUqACAuLg47duzAypUrsWjRojI/99hjj2HcuHFQKBTYunVrhbdHRERU3fr164eIiAgMHz4cr776Kpo2bYpLly4hISEBw4cPR6dOnTB37lz07dsXjRo1wpgxY2AymbB9+3Y8//zzDutbv349zGYzunTpAp1Ohw8++AAeHh4IDQ0tddtt2rTBQw89hLi4OJhMJsTExKBnz55lDlguSS6XY+jQoXj77bfx8ssvY/ny5Rg+fDh8fHyg0+nw1FNPISkpCSNHjsSiRYsQHR2NrKwsu3VERERg+/btGDBgAJRKJWbOnOlaMSvI6XDz9NNP200bjUbk5eVBrVZDp9NVONwYDAYcOnTIoYsqOjoaBw4cKPNz69atwz///IMPP/wQCxcudLb5RERE1UomkyEhIQFz5szB5MmTcfXqVQQFBaFHjx4IDAwEAPTq1QufffYZXnrpJSxevBg+Pj7o0aNHqeurVasWFi9ejNjYWJjNZrRu3Rpff/11qXdXl8lk2Lp1K5588kn06NEDcrkcAwYMsI0Pqqi5c+eiU6dOiIiIwJAhQ3DkyBFcvnwZPj4+UKlUeOqpp2zfpehwVkndunXDN998g0GDBkGhUNidvl7ZZOJ2z38DcOrUKTz++ON47rnn0L9/xY6XXrp0CfXr18cPP/yAyMhI2/xXXnkF77//Pv76669St/Ovf/0L+/btQ5MmTTBv3jxs3bq13DE3er3eNoobsJ6rHxISgvT0dPj4+NgtazQakZiYiKioqNu61frdhnVzDevmGtbNeTWxZgUFBTh//jzCwsLsxnPUJEIIZGdnw9vbmzf4hPXMqzFjxmDMmDF49NFH0bp1a8hkMvz555946623oNfrsWbNmtuqW0FBAc6ePYuQkBCH/SIrKwv+/v64ceOGw+/vkirl4Oa9996LxYsX4+GHH8aff/7p1GdLfvGyBj+ZzWaMGzcO8+fPR5MmTSq8/kWLFtmdWldk586dZV7BsaovLiRVrJtrWDfXsG7Oq0k1UyqVCAoKQk5ODgwGg7ubU67iF7O7m3Xu3Bl79+7F66+/jt69eyM7OxtyuRy1a9fGqFGj8N///tfucJQrdTMYDMjPz8f333/vcAZYXl5ehddTKT03AJCcnIyePXs6HGcri8FggE6nw2effYYRI0bY5j/99NM4fPgwkpKS7JbPzMxE7dq1oVDcHNFusVgghIBCocDOnTvRp08fh+2w56bqsW6uYd1cw7o5rybWjD03dzaLxWI7VTwwMNCuPndkz81XX31lNy2EQGpqKt5++21069atwutRq9Xo2LEjEhMT7cJNYmIihg0b5rC8j48Pjh07ZjcvPj4eu3fvxueff47w8PBSt6PRaGwXTSpOpVKV+UNe3ntUNtbNNayba1g359WkmpnNZshkMsjlcsjlTl9yrVoUjR0paifdJJfLUa9evVLfu526yeVyyGSyUvdVZ/Zdp8PN8OHD7aZlMhkCAgLQp08fvPHGG06tKzY2FuPHj7cNUlq9ejVSUlIwbdo0ANYrGl68eBEbNmyAXC63XUCoSN26daHVah3mExER0d3L6XBT1ihoV4wePRoZGRlYsGABUlNT0apVKyQkJNhOZ0tNTUVKSkqlbY+IiIikz+1XS4qJiUFMTEyp761fv77cz86bNw/z5s2r/EYRERHRHatC4SY2NrbCK1y6dKnLjSEiIiK6XRUKN8nJyRVaGUeTExERkbtVKNzs2bOnqttBREREVCl4bhsREdEdJiwszHbDSuDmbRZux969eyGTyZCZmXlb66kJXBpQfPDgQXz22WdISUlxuLLkli1bKqVhRERENdGkSZPw/vvvAwAUCgXq1auHwYMH45VXXkHt2rXd3Dp7Fy9exFtvvYVvv/0WFy5cgI+PDzp16oT//Oc/6Nevn7ubV2Wc7rn55JNP0K1bNxw/fhxffPEFjEYjjh8/jt27d8PX17cq2khERFSjDBgwAKmpqTh79izee+89fP3112We+esuH3/8MVq0aIFz585h7ty5+O6777Bx40Z07twZkydPxuTJkyv18i41idPh5pVXXsGyZcuwbds2qNVqLF++HCdOnMCoUaPQsGHDqmgjERFRjaLRaBAUFIQGDRogOjoao0ePxs6dO23vr1u3Ds2bN4dWq0WzZs0QHx9v9/kLFy5gzJgxqFOnDjw9PdGpUyf8/PPPAIB//vkHw4YNQ2BgILy8vHDfffdh165dTrUvISEBsbGx2LFjBzZu3IgRI0agbdu26NKlC5599lmcOHECly5dwgsvvFDmOvLz8zF48GB07doV165dc2r77ub0Yal//vkHgwcPBmD9x83NzYVMJsPMmTPRp0+fUm9SSUREdEtCAMaK3xyxUql0gItn/J4+fRrffvut7fYA7777LubOnYu3334b7du3R3JyMh599FF4enpi4sSJyMnJQc+ePVG/fn189dVXCAoKwm+//WbrRcnJycGgQYOwcOFCaLVavP/++7j//vvx119/VagTwWg0IiYmBuvXr0fXrl3x448/YubMmTh9+jT69euH4OBg+Pn54aOPPkLLli0RExPjsN4bN25gyJAh0Gq1+O677+Dp6elSbdzF6XBTp04d250+69evj99//x2tW7dGZmamU3fsJCIismPMA14p/X5FVe6FS4C64r/At23bBi8vL5jNZhQUFAC4eZ23l156CW+88QZGjhwJAAgPD8fx48exatUqTJw4ER9//DGuXr2KgwcPok6dOgCAxo0b29bdtm1btG3b1ja9cOFCfPHFF/jqq6/wxBNP3LJtSUlJ8Pf3x4ABA3Djxg0MHToUjz76KFatWoXdu3fj+eefx5w5c+Dn54eoqCgkJCTYbnsEAJcvX8bo0aPRqFEjbNy4EWq1usJ1qSkqHG4OHz6Mdu3aoXv37khMTETr1q0xatQoPP3009i9ezcSExPRt2/fqmwrERFRjdC7d2+sXLkSeXl5eO+993Dy5Ek8+eSTuHr1Ks6fP48pU6bg0UcftS1vMpls41IPHz6M9u3b24JNSbm5uZg/fz62bduGS5cuwWQyIT8/v8K3Izp69CgiIyMBAD/88ANq166NV155BYA1OH3zzTe2ZYODg3H9+nW7z/fr1w/33XcfPv30UygUiooXpQapcLjp0KED2rdvj+HDh2Ps2LEArDe2VKlU2L9/P0aOHIkXX3yxyhpKREQSp9JZe1DctW0neHp62npb3nzzTfTu3Rvz58+39ay8++676NKli91nioKCh4dHuet+7rnnsGPHDixZsgSNGzeGh4cHHnzwQYezk8tiMpmg1WoBAAaDATqd/Xfz8vKyvT5y5AimTJli9/7gwYOxefNmHD9+HK1bt67QNmuaCg8o/uGHH9ChQwcsWbIEjRo1wsMPP4ykpCQ8//zz+Oqrr7B06dIadwocERHdQWQy66Ehdzxu8wr7c+fOxZIlS2A2m1G/fn2cPn0ajRs3tnuEh4cDANq0aYPDhw+XOUh33759mDRpEkaMGIHWrVsjKCgIZ8+erXBbGjdujKNHjwIAOnfujJMnT2Lz5s2wWCzYv38/duzYAaPRiBUrVuD06dMYOnSo3ecXL16MiRMnom/fvjh+/LhrBXGzCoebiIgIvPvuu0hLS8PKlStx4cIF9OvXD40aNcLLL7+MCxcuVGU7iYiIaqxevXqhZcuWeOWVVzBv3jwsWrQIy5cvx8mTJ3Hs2DGsW7fONiZn7NixCAoKwvDhw/HDDz/g9OnT2Lx5M3788UcA1nCyZcsWHD58GEeOHMG4ceOcOmW7X79++OWXX3DixAnUq1fPNtZHrVZj2rRpGDlyJF599VV8/fXXSExMtPXyFLdkyRI89NBD6NOnD/7888/KKVI1cvpUcA8PD0ycOBF79+7FyZMnMXbsWKxatQrh4eEYNGhQVbSRiIioxouNjcW7776L/v3747333sP69evRunVr9OzZE+vXr7f13KjVauzcuRN169bFoEGD0Lp1ayxevNh22GrZsmWoXbs2IiMjcf/996N///7o0KFDhdvh4+OD2bNnY/To0bh69SrGjx+PzMxMnDt3DseOHcOKFSuQmZmJb7/9FmFhYWWuZ9myZRg1ahT69OmDkydP3lZtqp24TdnZ2eKdd94RderUEXK5/HZXV+Vu3LghAIgbN244vGcwGMTWrVuFwWBwQ8vuXKyba1g317BuzquJNcvPzxfHjx8X+fn57m5Kmcxms7h+/bowm83ubopLpk+fLurVqydWrlwp0tLShBBC5OXliW3btokuXbqIxMTEKtnu7dStvP2ivN/fJbl0+wXAeqrZ2rVrsXnzZigUCowaNcphUBIRERG5x9tvv40BAwbg1VdfxRNPPAGFQgGj0Yh27dohNjZW0rdfcCrcnD9/HuvXr8f69etx5swZREZG4q233sKoUaPuuAv8EBERSd2QIUMwZMgQ5Ofn4+rVq6hVqxZ8fHzc3awqV+FwExUVhT179iAgIAATJkzA5MmT0bRp06psGxEREVUCDw+Pu+oWSRUONx4eHti8eTOGDBlyx17Uh4iIiKSvwuHmq6++qsp2EBHRXUgI4e4mUA1SWfuD06eCExER3a6im0zynoRUXNFVmG/3CJHLZ0sRERG5SqFQoFatWrhy5QoAQKfTQXabVwmubBaLBQaDAQUFBZDL2RdQUa7WzWKx4OrVq9DpdFAqby+eMNwQEZFbBAUFAYAt4NQ0Qgjk5+fDw8OjxgWvmux26iaXy9GwYcPbrjfDDRERuYVMJkNwcDDq1q0Lo9Ho7uY4MBqN+P7779GjRw/bYTS6tdupm1qtrpReMoYbIiJyK4VCUSPPwlUoFLY7bDPcVFxNqBsPIhIREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkuD3cxMfHIzw8HFqtFh07dsS+ffvKXHb//v3o1q0b/Pz84OHhgWbNmmHZsmXV2FoiIiKq6dx6b6lNmzZhxowZiI+PR7du3bBq1SoMHDgQx48fR8OGDR2W9/T0xBNPPIE2bdrA09MT+/fvx2OPPQZPT0/85z//ccM3ICIioprGrT03S5cuxZQpUzB16lQ0b94ccXFxCAkJwcqVK0tdvn379hg7dixatmyJsLAwPPzww+jfv3+5vT1ERER0d3FbuDEYDDh06BCio6Pt5kdHR+PAgQMVWkdycjIOHDiAnj17VkUTiYiI6A7ktsNS6enpMJvNCAwMtJsfGBiItLS0cj/boEEDXL16FSaTCfPmzcPUqVPLXFav10Ov19ums7KyAABGoxFGo9Fu2aLpkvOpfKyba1g317BuzmPNXMO6uaaq6ubM+tw65gYAZDKZ3bQQwmFeSfv27UNOTg5++uknzJo1C40bN8bYsWNLXXbRokWYP3++w/ydO3dCp9OV+pnExMQKtp6KY91cw7q5hnVzHmvmGtbNNZVdt7y8vAov67Zw4+/vD4VC4dBLc+XKFYfenJLCw8MBAK1bt8bly5cxb968MsPN7NmzERsba5vOyspCSEgIoqOj4ePjY7es0WhEYmIioqKioFKpXPladyXWzTWsm2tYN+exZq5h3VxTVXUrOvJSEW4LN2q1Gh07dkRiYiJGjBhhm5+YmIhhw4ZVeD1CCLvDTiVpNBpoNBqH+SqVqsyil/celY11cw3r5hrWzXmsmWtYN9dUdt2cWZdbD0vFxsZi/Pjx6NSpEyIiIrB69WqkpKRg2rRpAKy9LhcvXsSGDRsAACtWrEDDhg3RrFkzANbr3ixZsgRPPvmk274DERER1SxuDTejR49GRkYGFixYgNTUVLRq1QoJCQkIDQ0FAKSmpiIlJcW2vMViwezZs3HmzBkolUo0atQIixcvxmOPPeaur0BEREQ1jNsHFMfExCAmJqbU99avX283/eSTT7KXhoiIiMrl9tsvEBEREVUmhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFLeHm/j4eISHh0Or1aJjx47Yt29fmctu2bIFUVFRCAgIgI+PDyIiIrBjx45qbC0RERHVdG4NN5s2bcKMGTMwZ84cJCcno3v37hg4cCBSUlJKXf77779HVFQUEhIScOjQIfTu3Rv3338/kpOTq7nlREREVFO5NdwsXboUU6ZMwdSpU9G8eXPExcUhJCQEK1euLHX5uLg4PP/887jvvvtw77334pVXXsG9996Lr7/+uppbTkRERDWV28KNwWDAoUOHEB0dbTc/OjoaBw4cqNA6LBYLsrOzUadOnapoIhEREd2BlO7acHp6OsxmMwIDA+3mBwYGIi0trULreOONN5Cbm4tRo0aVuYxer4der7dNZ2VlAQCMRiOMRqPdskXTJedT+Vg317BurmHdnMeauYZ1c01V1c2Z9bkt3BSRyWR200IIh3ml2bhxI+bNm4cvv/wSdevWLXO5RYsWYf78+Q7zd+7cCZ1OV+pnEhMTb7l9csS6uYZ1cw3r5jzWzDWsm2squ255eXkVXtZt4cbf3x8KhcKhl+bKlSsOvTklbdq0CVOmTMFnn32Gfv36lbvs7NmzERsba5vOyspCSEgIoqOj4ePjY7es0WhEYmIioqKioFKpnPxGdy/WzTWsm2tYN+exZq5h3VxTVXUrOvJSEW4LN2q1Gh07dkRiYiJGjBhhm5+YmIhhw4aV+bmNGzdi8uTJ2LhxIwYPHnzL7Wg0Gmg0Gof5KpWqzKKX9x6VjXVzDevmGtbNeayZa1g311R23ZxZl1sPS8XGxmL8+PHo1KkTIiIisHr1aqSkpGDatGkArL0uFy9exIYNGwBYg82ECROwfPlydO3a1dbr4+HhAV9fX7d9DyIiIqo53BpuRo8ejYyMDCxYsACpqalo1aoVEhISEBoaCgBITU21u+bNqlWrYDKZMH36dEyfPt02f+LEiVi/fn11N5+IiIhqILcPKI6JiUFMTEyp75UMLHv37q36BhEREdEdze23XyAiIiKqTAw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJClKdzeAiIiIqokQgEkPmPXWZ5MeMBsAU0Gx6cJnY771Ycov9rrg5mvbewWAMa/wvTwojfn4V4EMGDTIbV/T7eEmPj4er7/+OlJTU9GyZUvExcWhe/fupS6bmpqKZ555BocOHcKpU6fw1FNPIS4urnobTERE5AohrEGieEgoDAQwFtwMCkXz7MKGocRzUSgp7bnEcsXXYzZU+deUAfBU+lT5dsrj1nCzadMmzJgxA/Hx8ejWrRtWrVqFgQMH4vjx42jYsKHD8nq9HgEBAZgzZw6WLVvmhhYTEdEdSwjAbCwME/mFz8VfF3s25EGuz0aT1N8h33sYECbrZ82GwkdZr0vMswst+YCwuLsK9hQaQFn4sHutBlQ6QKW1Piu1gMrD+lBqy3nPAya5Cj/9chjd3Pi13Bpuli5diilTpmDq1KkAgLi4OOzYsQMrV67EokWLHJYPCwvD8uXLAQBr166t1rYSEVEVKDpMUjJwGPKKhY8SAaHokImt90N/i/cLbq5PmCvcNAWA5gCQVhVfXOYYFJQehc/am+/ZQoe6jGdtKfMKw0mpoaVEgJHJKv2bCaMRN37PrPT1OsNt4cZgMODQoUOYNWuW3fzo6GgcOHCg0raj1+uh1+tt01lZWQAAo9EIo9Fot2zRdMn5VD7WzTWsm2tYN+dVec2MeUBeBmS56UBeeuHrq9bnvAwgL8MWVGR2vSS5gDEfMjf0ZgiZAlDrCgOFDlB5QBTrfYDaExaFBudTr6JB2D2Qq7SAXA0oVNZQUOxZFJ+WF80vnKfUQBT1bhQPLVUULCpeAAAmU5Wsuqr2N2fW57Zwk56eDrPZjMDAQLv5gYGBSEurvJi8aNEizJ8/32H+zp07odPpSv1MYmJipW3/bsK6uYZ1cw3r5jy7mgkLFBYjFMIAucVge62wGK3TwgiFxWB7rTLlQmPKhtqUBY0pq9jrbCgt+rI36gSLTAGzXAOTXAOzXA1z0bNMXTithkWmKnytKva6lGmZGha5Cma5qnA91nWZZNb1CpmiYuGiIXDUAsCpr2gofNzdKvtnNC8vr8LLun1AsazEziWEcJh3O2bPno3Y2FjbdFZWFkJCQhAdHQ0fH/sBT0ajEYmJiYiKioJKpaq0Nkgd6+Ya1s01d13dDLlAZgpkmecAfRZgKoDMVDTotPC58CGzzSs6VFMAmTEfwpiP/JxM6FQy2+dklsr9q1oo1IDOD9D5Q3j6Azo/CJ2/dVpXB1B7FvaQWB/WXhJd4VgNT+uzwvrvqUQN+OWEu3BfqyRVVbeiIy8V4bb9x9/fHwqFwqGX5sqVKw69ObdDo9FAo9E4zFepVGUWvbz3qGysm2tYN9dIpm5mI3DjApB5Drh+Frh+zv51Xvptb0IGwBMouzNBoS522KRw7IdSU2xMiAeg8QE8AwBPa4CxvraGGHgGQKbxtvWEuPFgS5WQzL5WzSq7bs6sy23hRq1Wo2PHjkhMTMSIESNs8xMTEzFs2DB3NYuIqPIZcoH0k0D639bQknnWGlyunwOyLt56kKvWF6gVCujqFBt0WkoAKRlQCgenmmRKHPglGRE9+kDl4V04oLTY4FW5ojqqQFRt3NrzFxsbi/Hjx6NTp06IiIjA6tWrkZKSgmnTpgGwHlK6ePEiNmzYYPvM4cOHAQA5OTm4evUqDh8+DLVajRYtWrjjKxAR3aTPsYaYq39aH1cKnzNTYB3BWQaFBqgdag0wtuewm689at1Ws4TRiOt/ZAGBLQH2QNBdwK3hZvTo0cjIyMCCBQuQmpqKVq1aISEhAaGhoQCsF+1LSUmx+0z79u1trw8dOoSPP/4YoaGhOHv2bHU2nYjuZvocIP2vm+HlavEQUwadP+DfBKgTfjPE1A6zvvYKBOS8Gw5RZXH7mK2YmBjExMSU+t769esd5glRzl8/RESVwWwCslOtY2FunLc+Mgufr54EbpQTYjwDgIBmhY+mQN3m1tee/tXXfqK7nNvDDRFRtTPkFg7iPW8NKrbXhWEm69Ktx8F41i0WXpoCAUUhxq96vgMRlYnhhoikRQjrReMyUwp7XS7c7HXJLAwy+dduvR65CvCtD/iGFD4aALVCAL/G1hCjq1P134WIXMJwQ0R3FosJHoZ0yFJ+BHJSrT0vxXtdblywXgH3VjS+1rDi28A+vBSFGY6DIbpjMdwQUc1gyAWy04CcK0DO5ZuP7Mt208rcq4gWFuCPW6zPK+hmWCkeWooCjda3Wr4WEVU/hhsiqnqGXOv1Xa6dAa6dtl7bpWRwMeRUaFUyWC/TL/MNgaxWCFCroX2AqRUC+NS3XsuFiO5KDDdEdPuEAPKvW4PLtTPA9TPFnk9bw0tFqHTWw0FegYB34M3XxeYZNXWQ8P2vGDR4CK8aS0SlYrghoorLu1Z4pd1ThUHmdGGAOQvob5T/WW0t6zVeaodbe1u8gxyCC9Ret76ZodEIyDgWhojKxnBDRPYsZuu9jdJPFQaZkzdf52WU/1nvYKDOPdYAUyes8Pkea6jxqF0tzSciYrghulvpc4CMU44hJuNvwFzWHRZhHdfi1xjwa1QYXgoDTK1QQK2rvvYTEZWB4YZIaswmIPeK9cyj7DTrlXaz04CcEtO5V8teh1JrDTD+91pvGeDfxPrarzGg9qy+70JE5AKGG6I7gUlvHe+Sf63Yc4b1bKOisJKdWnjm0RWUe5PG4jzr3gwuxUOMbwiv8UJEdyyGG6LqZswHctMhu5GKullHIfs9F9BnOQaXvGvWM5DyrgHGXOe2IVMUDtINso6D8Q4sfC6c9gq0njLNcTBEJEEMN0S3y2QA8tKB3HTroZ7c9MLpq4WPDOtz0TKF13NRAogAgH8quB2Z3BpGPOpYL/3vUacwrAQVCzGFzzo/QK6ooi9MRFSzMdwQlcaQaz28UxRQil7nXLGOZ8m5an3OvQoU3OIU6NIo1BA6P2SZVPAODIVc53czsJT6XNt6KjUPFRER3RLDDd0dTPrCQz0ZhT0rxV7bBZjC4OL0YSA5oPMHPAOsd4X2DLA+dP6AZ9H8Ys8aH5hMJuxNSMCgQYMg58XoiIgqDcMN3RnMRuvNEI0Fhc/5gCnf+qzPuXnIxyHApFvHrOiznN+mUmsdcOsVcDOseNUtNq/uzXnsVSEiqjEYbsg9LBbgyh/AuQPA+V+sA2eLBxZbkCmcZzHd/jZlCushHp2/dUyKp1/hc8ngUhhaNN63vlouERHVOAw3VD3MRiD1KHDuB2ugSTng2lgVmdx6/yGl1vqs8rBeOM4WWAqf7V77W0MNe1eIiO4KDDdUNYwFwKXfrGHm7A/W3pmS41jUXkBIFyA0AvBpAKiKBRZbgCl8XfSeQs3eFCIiKhfDDVUKhVkP2Zkk4MJP1p6ZC78CZr39QtpaQGg3IDTS+ghqAyi4CxIRUeXibxYqncUM5GfeHKDr8Lhme63My8Cg6ymQHzXbr8OzLhDW7WagCWjOw0JERFTlGG7uZiYDcCnZOv7l4iHrKdBF4SX/Oip6CX9Z4UP4hkBm65npZr2xIg8hERFRNWO4uZvos61jX1J+BM79CFz8FTAVlP8Zre/NAbq2Rx27aZPaF98dOok+w8dDxeu1EBGRmzHcSFnOVWuQSfnROg4m7SggLPbL6PyAhhFAw65ArYb2IcajNqC4dVgRRiMKjmVU0ZcgIiJyDsONVAgBZJ6z9sikHLA+Z5xyXK5WQ6BhpPUMpYaR1jtA89ARERFJCMONuxjybt5ksejy/3kZNy9aZ9IXvi6wPowF5cwvvNidxei4nbotrD0zoZHWZ9/61f9diYiIqhHDTWWxWErcCbr46xLTrty7qCLkSqBe+5thJqSLdXwMERHRXYThprJkngXebO/cZxSawkv9F95QUed38yJ2Sm3hRey0xV57AEoNoPQofb7Oz/qaiIjoLsZwU1k8AwDIrD0lRfcqst0FuuTDn/cuIiIiqiIMN5VF7QW8mM4r7hIREbkZLxdbWWQyBhsiIqIagOGGiIiIJIXhhoiIiCSF4YaIiIgkheGGiIiIJMXt4SY+Ph7h4eHQarXo2LEj9u3bV+7ySUlJ6NixI7RaLe655x6888471dRSIiIiuhO4Ndxs2rQJM2bMwJw5c5CcnIzu3btj4MCBSElJKXX5M2fOYNCgQejevTuSk5Pxwgsv4KmnnsLmzZurueVERERUU7k13CxduhRTpkzB1KlT0bx5c8TFxSEkJAQrV64sdfl33nkHDRs2RFxcHJo3b46pU6di8uTJWLJkSTW3nIiIiGoqt12YxWAw4NChQ5g1a5bd/OjoaBw4cKDUz/z444+Ijo62m9e/f3+sWbMGRqMRKpXK4TN6vR56vd42nZWVBQAwGo0wGu1vNFk0XXI+lY91cw3r5hrWzXmsmWtYN9dUVd2cWZ/bwk16ejrMZjMCAwPt5gcGBiItLa3Uz6SlpZW6vMlkQnp6OoKDgx0+s2jRIsyfP99h/s6dO6HT6UrdTmJiYkW/BhXDurmGdXMN6+Y81sw1rJtrKrtueXl5FV7W7ZfUlZW4t5IQwmHerZYvbX6R2bNnIzY21jadlZWFkJAQREdHw8fHx25Zo9GIxMREREVFldoLRKVj3VzDurmGdXMea+Ya1s01VVW3oiMvFeG2cOPv7w+FQuHQS3PlyhWH3pkiQUFBpS6vVCrh5+dX6mc0Gg00Go3DfJVKVWbRy3uPysa6uYZ1cw3r5jzWzDWsm2squ27OrMttA4rVajU6duzo0G2VmJiIyMjIUj8TERHhsPzOnTvRqVMn7nhEREQEwM1nS8XGxuK9997D2rVrceLECcycORMpKSmYNm0aAOshpQkTJtiWnzZtGs6dO4fY2FicOHECa9euxZo1a/Dss8+66ysQERFRDePWMTejR49GRkYGFixYgNTUVLRq1QoJCQkIDQ0FAKSmptpd8yY8PBwJCQmYOXMmVqxYgXr16uHNN9/EAw88UOFtFo3RKe3YndFoRF5eHrKystgT5ATWzTWsm2tYN+exZq5h3VxTVXUr+r1d9Hu8PDJRkaUk5MKFCwgJCXF3M4iIiMgF58+fR4MGDcpd5q4LNxaLBZcuXYK3t7fDGVZFZ1KdP3/e4UwqKhvr5hrWzTWsm/NYM9ewbq6pqroJIZCdnY169epBLi9/VI3bTwWvbnK5/JaJz8fHhzuyC1g317BurmHdnMeauYZ1c01V1M3X17dCy7n9xplERERElYnhhoiIiCSF4aYYjUaDuXPnlnrRPyob6+Ya1s01rJvzWDPXsG6uqQl1u+sGFBMREZG0seeGiIiIJIXhhoiIiCSF4YaIiIgkheGGiIiIJIXhppj4+HiEh4dDq9WiY8eO2Ldvn7ubVKPNmzcPMpnM7hEUFOTuZtU433//Pe6//37Uq1cPMpkMW7dutXtfCIF58+ahXr168PDwQK9evfDHH3+4p7E1xK1qNmnSJId9r2vXru5pbA2xaNEi3HffffD29kbdunUxfPhw/PXXX3bLcF9zVJG6cX9ztHLlSrRp08Z2ob6IiAhs377d9r679zWGm0KbNm3CjBkzMGfOHCQnJ6N79+4YOHCg3Y07yVHLli2Rmppqexw7dszdTapxcnNz0bZtW7z99tulvv/aa69h6dKlePvtt3Hw4EEEBQUhKioK2dnZ1dzSmuNWNQOAAQMG2O17CQkJ1djCmicpKQnTp0/HTz/9hMTERJhMJkRHRyM3N9e2DPc1RxWpG8D9raQGDRpg8eLF+PXXX/Hrr7+iT58+GDZsmC3AuH1fEySEEKJz585i2rRpdvOaNWsmZs2a5aYW1Xxz584Vbdu2dXcz7igAxBdffGGbtlgsIigoSCxevNg2r6CgQPj6+op33nnHDS2seUrWTAghJk6cKIYNG+aW9twprly5IgCIpKQkIQT3tYoqWTchuL9VVO3atcV7771XI/Y19twAMBgMOHToEKKjo+3mR0dH48CBA25q1Z3h1KlTqFevHsLDwzFmzBicPn3a3U26o5w5cwZpaWl2+55Go0HPnj25793C3r17UbduXTRp0gSPPvoorly54u4m1Sg3btwAANSpUwcA97WKKlm3ItzfymY2m/HJJ58gNzcXERERNWJfY7gBkJ6eDrPZjMDAQLv5gYGBSEtLc1Orar4uXbpgw4YN2LFjB959912kpaUhMjISGRkZ7m7aHaNo/+K+55yBAwfio48+wu7du/HGG2/g4MGD6NOnD/R6vbubViMIIRAbG4t//etfaNWqFQDuaxVRWt0A7m9lOXbsGLy8vKDRaDBt2jR88cUXaNGiRY3Y1+66u4KXRyaT2U0LIRzm0U0DBw60vW7dujUiIiLQqFEjvP/++4iNjXVjy+483PecM3r0aNvrVq1aoVOnTggNDcU333yDkSNHurFlNcMTTzyBo0ePYv/+/Q7vcV8rW1l14/5WuqZNm+Lw4cPIzMzE5s2bMXHiRCQlJdned+e+xp4bAP7+/lAoFA6J8sqVKw7Jk8rm6emJ1q1b49SpU+5uyh2j6Owy7nu3Jzg4GKGhodz3ADz55JP46quvsGfPHjRo0MA2n/ta+cqqW2m4v1mp1Wo0btwYnTp1wqJFi9C2bVssX768RuxrDDew/gN17NgRiYmJdvMTExMRGRnpplbdefR6PU6cOIHg4GB3N+WOER4ejqCgILt9z2AwICkpifueEzIyMnD+/Pm7et8TQuCJJ57Ali1bsHv3boSHh9u9z32tdLeqW2m4v5VOCAG9Xl8z9rVqGbZ8B/jkk0+ESqUSa9asEcePHxczZswQnp6e4uzZs+5uWo31zDPPiL1794rTp0+Ln376SQwZMkR4e3uzZiVkZ2eL5ORkkZycLACIpUuXiuTkZHHu3DkhhBCLFy8Wvr6+YsuWLeLYsWNi7NixIjg4WGRlZbm55e5TXs2ys7PFM888Iw4cOCDOnDkj9uzZIyIiIkT9+vXv6po9/vjjwtfXV+zdu1ekpqbaHnl5ebZluK85ulXduL+Vbvbs2eL7778XZ86cEUePHhUvvPCCkMvlYufOnUII9+9rDDfFrFixQoSGhgq1Wi06dOhgdyogORo9erQIDg4WKpVK1KtXT4wcOVL88ccf7m5WjbNnzx4BwOExceJEIYT1FN25c+eKoKAgodFoRI8ePcSxY8fc22g3K69meXl5Ijo6WgQEBAiVSiUaNmwoJk6cKFJSUtzdbLcqrV4AxLp162zLcF9zdKu6cX8r3eTJk22/LwMCAkTfvn1twUYI9+9rMiGEqJ4+IiIiIqKqxzE3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0QkCb169cKMGTPc3QwiqgEYboiIiEhSGG6IiIhIUhhuiEiSvv32W/j6+mLDhg3ubgoRVTOGGyKSnE8++QSjRo3Chg0bMGHCBHc3h4iqGcMNEUlKfHw8pk2bhi+//BLDhg1zd3OIyA2U7m4AEVFl2bx5My5fvoz9+/ejc+fO7m4OEbkJe26ISDLatWuHgIAArFu3DkIIdzeHiNyE4YaIJKNRo0bYs2cPvvzySzz55JPubg4RuQkPSxGRpDRp0gR79uxBr169oFQqERcX5+4mEVE1Y7ghIslp2rQpdu/ejV69ekGhUOCNN95wd5OIqBrJBA9MExERkYRwzA0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUkKww0RERFJCsMNERERSQrDDREREUnK/wO/WB2QWC/CSgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_precision_recall_at_k_range(model, data, k_range, threshold=91):\n",
    "    k_fold = KFold(n_splits=5, random_state=42)\n",
    "    precision_k_values = []\n",
    "    recall_k_values = []\n",
    "\n",
    "    for k in k_range:\n",
    "        precisions_list = []\n",
    "        recalls_list = []\n",
    "\n",
    "        for trainset, testset in k_fold.split(data):\n",
    "            model.fit(trainset)\n",
    "            predictions = model.test(testset)\n",
    "            precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=threshold)\n",
    "\n",
    "            precisions_list.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "            recalls_list.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "\n",
    "        precision_k_values.append(sum(precisions_list) / len(precisions_list))\n",
    "        recall_k_values.append(sum(recalls_list) / len(recalls_list))\n",
    "\n",
    "    return precision_k_values, recall_k_values\n",
    "\n",
    "# Create an instance of the SVD model with default parameters\n",
    "default_svd = SVD(random_state=42)\n",
    "\n",
    "k_range = range(1, 31)  # Vary the value of k from 1 to 30\n",
    "\n",
    "# Pass the default_svd model to the function instead of the tuned_svd model\n",
    "precision_values, recall_values = get_precision_recall_at_k_range(default_svd, data, k_range)\n",
    "\n",
    "# Plot the precision and recall values against the value of k\n",
    "plt.plot(k_range, precision_values, label=\"Precision@k\")\n",
    "plt.plot(k_range, recall_values, label=\"Recall@k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Precision and Recall at varying k values\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may observe that as k increases, Precision@k hovers around 0.7 and Recall@k increases marginally to 0.1.\n",
    "\n",
    "In other words, if a user is given 10 recommendations, 7 of those recommendations would be wines that the user might enjoy or find suitable, and on average, the recommender is only able to identify about 1 out of all relevant wines for a user within the top 10 recommendations. \n",
    "\n",
    "As there is no significant improvement in Precision@k and Recall@k, we will not vary the value of k for our default SVD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_thresholds(default_svd, data, thresholds):\n",
    "    results = []\n",
    "    for threshold in thresholds:\n",
    "        k_fold = KFold(n_splits=5, random_state=42)\n",
    "        precisions_list = []\n",
    "        recalls_list = []\n",
    "\n",
    "        for trainset, testset in k_fold.split(data):\n",
    "            default_svd.fit(trainset)\n",
    "            predictions = default_svd.test(testset)\n",
    "            precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=threshold)\n",
    "\n",
    "            precisions_list.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "            recalls_list.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "\n",
    "        precision = sum(precisions_list) / len(precisions_list)\n",
    "        recall = sum(recalls_list) / len(recalls_list)\n",
    "        results.append({\n",
    "            'Threshold': threshold,\n",
    "            'Precision@k': precision,\n",
    "            'Recall@k': recall,\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['F1-score'] = 2 * (results_df['Precision@k'] * results_df['Recall@k']) / (results_df['Precision@k'] + results_df['Recall@k'])\n",
    "    results_df = results_df[['Threshold', 'Precision@k', 'Recall@k', 'F1-score']]\n",
    "    return results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborative Filtering Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wines with desired attribute(s): 17\n",
      "Top 10 Recommendations for new user with Desired Attributes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine_id</th>\n",
       "      <th>estimated_rating</th>\n",
       "      <th>title</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87272</td>\n",
       "      <td>91.70127</td>\n",
       "      <td>Rosenhof 2015 Orion Eiswein Grner Veltliner (...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115007</td>\n",
       "      <td>91.70127</td>\n",
       "      <td>Dr. Loosen 2009 rziger Wrzgarten Auslese Rie...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122068</td>\n",
       "      <td>91.70127</td>\n",
       "      <td>Tapteil Vineyard 2011 Argus Bone Dry Riesling ...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185700</td>\n",
       "      <td>91.70127</td>\n",
       "      <td>Emile Beyer 2016 Tradition Gewurztraminer (Als...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6595</td>\n",
       "      <td>91.70127</td>\n",
       "      <td>Fiddlehead 2014 Goosebury Sauvignon Blanc (San...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95923</td>\n",
       "      <td>91.70127</td>\n",
       "      <td>Qup 2015 Sawyer-Lindquist Vineyard Marsanne (...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>192142</td>\n",
       "      <td>91.70127</td>\n",
       "      <td>Dr. Heidemanns-Bergweiler 2016 Bernkasteler al...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150610</td>\n",
       "      <td>91.70127</td>\n",
       "      <td>Lincourt 2014 Courtney's Chardonnay (Sta. Rita...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>164023</td>\n",
       "      <td>91.70127</td>\n",
       "      <td>Weingut Binz 2015 Nackenheimer Engelsberg Beer...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>206665</td>\n",
       "      <td>91.70127</td>\n",
       "      <td>Grard Bertrand 2019 Cte des Roses Ros (Lang...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wine_id  estimated_rating  \\\n",
       "0    87272          91.70127   \n",
       "1   115007          91.70127   \n",
       "2   122068          91.70127   \n",
       "3   185700          91.70127   \n",
       "4     6595          91.70127   \n",
       "5    95923          91.70127   \n",
       "6   192142          91.70127   \n",
       "7   150610          91.70127   \n",
       "8   164023          91.70127   \n",
       "9   206665          91.70127   \n",
       "\n",
       "                                               title  points  \n",
       "0  Rosenhof 2015 Orion Eiswein Grner Veltliner (...      95  \n",
       "1  Dr. Loosen 2009 rziger Wrzgarten Auslese Rie...      94  \n",
       "2  Tapteil Vineyard 2011 Argus Bone Dry Riesling ...      92  \n",
       "3  Emile Beyer 2016 Tradition Gewurztraminer (Als...      92  \n",
       "4  Fiddlehead 2014 Goosebury Sauvignon Blanc (San...      92  \n",
       "5  Qup 2015 Sawyer-Lindquist Vineyard Marsanne (...      91  \n",
       "6  Dr. Heidemanns-Bergweiler 2016 Bernkasteler al...      91  \n",
       "7  Lincourt 2014 Courtney's Chardonnay (Sta. Rita...      91  \n",
       "8  Weingut Binz 2015 Nackenheimer Engelsberg Beer...      91  \n",
       "9  Grard Bertrand 2019 Cte des Roses Ros (Lang...      91  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a new user\n",
    "new_user_id = df['user_id'].max() + 1\n",
    "\n",
    "# Define attributes\n",
    "desired_attributes = {'light', 'sweet', 'citrus'}\n",
    "\n",
    "# Sort wines by points in descending order\n",
    "df_sorted = df.sort_values('points', ascending=False)\n",
    "\n",
    "# Filter wines based on desired attributes\n",
    "filtered_wines = df_sorted[df_sorted['tokens'].apply(lambda tokens: all(attribute in tokens for attribute in desired_attributes))]\n",
    "\n",
    "print(\"Number of wines with desired attribute(s):\", len(filtered_wines))\n",
    "\n",
    "# Generate predicted ratings for the new user for each filtered wine\n",
    "predicted_ratings = []\n",
    "for wine_id in filtered_wines['wine_id']:\n",
    "    predicted_rating = default_svd.predict(new_user_id, wine_id)\n",
    "    predicted_ratings.append((wine_id, predicted_rating.est))\n",
    "\n",
    "# Sort the wines based on the predicted ratings\n",
    "sorted_predicted_ratings = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Retrieve the top 10 recommendations\n",
    "top_10_recommendations = sorted_predicted_ratings[:10]\n",
    "\n",
    "# Compare the estimated ratings to the actual ratings\n",
    "recommended_wines = pd.DataFrame(top_10_recommendations, columns=['wine_id', 'estimated_rating'])\n",
    "recommended_wines = recommended_wines.merge(df[['wine_id', 'title', 'points']], on='wine_id')\n",
    "\n",
    "# Sort by 'points' in descending order\n",
    "recommended_wines = recommended_wines.sort_values(by='points', ascending=False)\n",
    "\n",
    "print(\"Top 10 Recommendations for new user with Desired Attributes:\")\n",
    "recommended_wines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we have the same estimated rating for all recommendations?\n",
    "\n",
    "Since our new user has no historical rating data, the model falls back to its global mean and biases, which results in the same predicted ratings for all wines.\n",
    "\n",
    "We will now incorporate content-based features into the model, creating a hybrid recommendation system. This approach would allow it to provide more diverse recommendations based on both collaborative filtering and content-based information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tokens into a single string for each wine\n",
    "df['tokens_str'] = df['tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Create a TfidfVectorizer\n",
    "tvec = TfidfVectorizer(min_df=5, max_df=0.95, max_features=200, ngram_range=(1, 2), sublinear_tf=True)\n",
    "\n",
    "# Fit the vectorizer to the 'tokens' column and transform the tokens into vectors\n",
    "tmat = tvec.fit_transform(df['tokens_str'])\n",
    "\n",
    "# Get the vocabulary\n",
    "tfidf_vocab = tvec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fruit', 'tannin', 'black', 'cherry', 'ripe', 'aroma', 'rich', 'spice', 'full', 'red', 'oak', 'note', 'blackberry', 'plum', 'berry', 'fresh', 'dark', 'dry', 'apple', 'bodied', 'lemon', 'white', 'juicy', 'balanced', 'herb', 'firm', 'raspberry', 'black cherry', 'pepper', 'bright', 'year', 'full bodied', 'cabernet', 'citrus', 'pear', 'vanilla', 'light', 'chocolate', 'dried', 'crisp', 'mineral', 'black fruit', 'peach', 'balance', 'currant', 'dense', 'aging', 'wood', 'soft', 'savory', 'complex', 'sweet', 'spicy', 'elegant', 'smooth', 'licorice', 'vintage', 'orange', 'green', 'sauvignon', 'tobacco', 'strawberry', 'leather', 'fruity', 'pinot', 'wine', 'earthy', 'lime', 'creamy', 'vineyard', 'tart', 'lead', 'cassis', 'hint', 'clove', 'young', 'syrah', 'tannic', 'intense', 'grape', 'flower', 'minerality', 'earth', 'stone', 'medium', 'tight', 'toast', 'complexity', 'powerful', 'cabernet sauvignon', 'barrel', 'merlot', 'layer', 'yellow', 'textured', 'come', 'smoky', 'there', 'grapefruit', 'rose', 'cranberry', 'well', 'cinnamon', 'blueberry', 'black currant', 'open', 'aged', 'coffee', 'cola', 'red fruit', 'violet', 'floral', 'chardonnay', 'tangy', 'anise', 'high', 'vine', 'bold', 'mouth', 'weight', 'baked', 'cedar', 'lush', 'herbal', 'scent', 'peel', 'smoke', 'tone', 'mouthfeel', 'body', 'layered', 'toasty', 'color', 'black pepper', 'depth', 'red cherry', 'apricot', 'black plum', 'mix', 'baking', 'honey', 'zest', 'offering', 'rounded', 'clean', 'baking spice', 'velvety', 'polished', 'old', 'strong']\n"
     ]
    }
   ],
   "source": [
    "# Calculate average tf-idf values for each feature\n",
    "average_tfidf = np.mean(tmat, axis=0).A1\n",
    "\n",
    "# Sort the features by their average tf-idf values in descending order\n",
    "sorted_indices = np.argsort(average_tfidf)[::-1]\n",
    "\n",
    "# Select the top 150 features\n",
    "top_features = sorted_indices[:150]\n",
    "\n",
    "# Get the feature names for the top 150 features\n",
    "attributes = [tfidf_vocab[index] for index in top_features]\n",
    "\n",
    "print(attributes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above features are our tokens with the highest average TF-IDF values, which will be used as an input for our Streamlit app to allow users to select their desired wine attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate cosine similarity between each wine's tokens and user desired attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calculating cosine similarity, we can find wines that are most similar to the user's desired attributes.\n",
    "\n",
    "By combining the predicted ratings for each wine (based on the user's preference) with these cosine similarity scores, we can then create a hybrid recommendation score.\n",
    "\n",
    "This approach effectively takes both content-based and collaborative filtering into account, resulting in a hybrid recommendation system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map wine_id to index\n",
    "wine_id_to_index = df.reset_index().set_index('wine_id')['index'].to_dict()\n",
    "\n",
    "# Define a function to compute cosine similarity\n",
    "def calculate_cosine_similarity(wine_id, desired_attributes):\n",
    "    wine_vector = tmat[df.index.get_loc(wine_id)]\n",
    "\n",
    "     # Filter out attributes that are not in the vocabulary\n",
    "    filtered_attributes = [attribute for attribute in desired_attributes if attribute in tfidf_vocab]\n",
    "\n",
    "    # If all attributes are not in the vocabulary, return 0 as the similarity\n",
    "    if not filtered_attributes:\n",
    "        return 0\n",
    "    \n",
    "    desired_attributes_vector = tvec.transform([' '.join(desired_attributes)])\n",
    "    similarity = cosine_similarity(wine_vector, desired_attributes_vector)\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to scale a value to a specified range\n",
    "def scale_value(value, old_min, old_max, new_min, new_max):\n",
    "    return ((value - old_min) * (new_max - new_min)) / (old_max - old_min) + new_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommendations(user_id, desired_attributes, n=10):\n",
    "    \n",
    "    # Get predicted ratings for all wines\n",
    "    predicted_ratings = []\n",
    "    for wine_id in df['wine_id']:\n",
    "        predicted_rating = default_svd.predict(user_id, wine_id)\n",
    "        predicted_ratings.append((wine_id, predicted_rating.est))\n",
    "    \n",
    "    # Calculate cosine similarity between desired_attributes and wine tokens\n",
    "    similarities = []\n",
    "    for wine_id in df['wine_id']:\n",
    "        similarity = calculate_cosine_similarity(wine_id, desired_attributes)\n",
    "        similarities.append((wine_id, similarity))\n",
    "    \n",
    "    # Calculate combined ratings\n",
    "    combined_ratings = []\n",
    "    for i, wine_id in enumerate(df['wine_id']):\n",
    "        scaled_similarity = scale_value(similarities[i][1], 0, 1, 90, 100)\n",
    "        combined_rating = predicted_ratings[i][1] * 0.8 + scaled_similarity * 0.2\n",
    "        combined_ratings.append((wine_id, combined_rating))\n",
    "    \n",
    "    # Filter out wines that do not contain all desired attributes\n",
    "    combined_ratings_filtered = [(wine_id, rating) for wine_id, rating in combined_ratings if all(attribute in df.loc[wine_id_to_index[wine_id], 'tokens'] for attribute in desired_attributes)]\n",
    "\n",
    "    # If there are no wines with the desired attributes, return the top 10 recommendations based on predicted ratings\n",
    "    if not combined_ratings_filtered:\n",
    "        sorted_predicted_ratings = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)\n",
    "        top_recommendations = sorted_predicted_ratings[:n]\n",
    "    else:\n",
    "        # Sort the wines based on the combined ratings\n",
    "        sorted_combined_ratings = sorted(combined_ratings_filtered, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Retrieve the top 10 recommendations\n",
    "        top_recommendations = sorted_combined_ratings[:n]\n",
    "\n",
    "    # Create a dataframe with the recommended wines\n",
    "    recommended_wines = pd.DataFrame(top_recommendations, columns=['wine_id', 'combined_rating'])\n",
    "    recommended_wines = recommended_wines.merge(df[['wine_id', 'title', 'points', 'variety']], on='wine_id')\n",
    "\n",
    "    # Remove duplicate titles\n",
    "    recommended_wines = recommended_wines.drop_duplicates(subset=['title'])\n",
    "\n",
    "    # Get the top 10 unique recommendations\n",
    "    recommended_wines = recommended_wines.head(10)\n",
    "\n",
    "    return recommended_wines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the 80% weightage for predicted ratings and 20% weightage for cosine similarity is arbitrary. \n",
    "\n",
    "After experimenting with an equal weightage, the results appeared too skewed towards the cosine similarity. \n",
    "\n",
    "Hence, I decided to increase the weightage for predicted ratings to 80% and decrease the weightage for cosine similarity to 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wines with desired attribute(s): 17\n",
      "Top 10 Recommendations for new user with Desired Attributes (Hybrid Approach):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine_id</th>\n",
       "      <th>combined_rating</th>\n",
       "      <th>title</th>\n",
       "      <th>points</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8775</td>\n",
       "      <td>92.849384</td>\n",
       "      <td>Lincourt 2014 Courtney's Chardonnay (Sta. Rita...</td>\n",
       "      <td>91</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95923</td>\n",
       "      <td>92.588226</td>\n",
       "      <td>Qup 2015 Sawyer-Lindquist Vineyard Marsanne (...</td>\n",
       "      <td>91</td>\n",
       "      <td>Marsanne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115007</td>\n",
       "      <td>92.565362</td>\n",
       "      <td>Dr. Loosen 2009 rziger Wrzgarten Auslese Rie...</td>\n",
       "      <td>94</td>\n",
       "      <td>Riesling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>164023</td>\n",
       "      <td>92.402026</td>\n",
       "      <td>Weingut Binz 2015 Nackenheimer Engelsberg Beer...</td>\n",
       "      <td>91</td>\n",
       "      <td>Riesling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>185700</td>\n",
       "      <td>92.385756</td>\n",
       "      <td>Emile Beyer 2016 Tradition Gewurztraminer (Als...</td>\n",
       "      <td>92</td>\n",
       "      <td>Gewrztraminer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6595</td>\n",
       "      <td>92.374515</td>\n",
       "      <td>Fiddlehead 2014 Goosebury Sauvignon Blanc (San...</td>\n",
       "      <td>92</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34864</td>\n",
       "      <td>92.354258</td>\n",
       "      <td>Beresan 2007 Smillon (Walla Walla Valley (WA))</td>\n",
       "      <td>90</td>\n",
       "      <td>Smillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>206665</td>\n",
       "      <td>92.273454</td>\n",
       "      <td>Grard Bertrand 2019 Cte des Roses Ros (Lang...</td>\n",
       "      <td>91</td>\n",
       "      <td>Ros</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wine_id  combined_rating  \\\n",
       "0     8775        92.849384   \n",
       "2    95923        92.588226   \n",
       "4   115007        92.565362   \n",
       "5   164023        92.402026   \n",
       "6   185700        92.385756   \n",
       "7     6595        92.374515   \n",
       "8    34864        92.354258   \n",
       "9   206665        92.273454   \n",
       "\n",
       "                                               title  points          variety  \n",
       "0  Lincourt 2014 Courtney's Chardonnay (Sta. Rita...      91       Chardonnay  \n",
       "2  Qup 2015 Sawyer-Lindquist Vineyard Marsanne (...      91         Marsanne  \n",
       "4  Dr. Loosen 2009 rziger Wrzgarten Auslese Rie...      94         Riesling  \n",
       "5  Weingut Binz 2015 Nackenheimer Engelsberg Beer...      91         Riesling  \n",
       "6  Emile Beyer 2016 Tradition Gewurztraminer (Als...      92   Gewrztraminer  \n",
       "7  Fiddlehead 2014 Goosebury Sauvignon Blanc (San...      92  Sauvignon Blanc  \n",
       "8    Beresan 2007 Smillon (Walla Walla Valley (WA))      90         Smillon  \n",
       "9  Grard Bertrand 2019 Cte des Roses Ros (Lang...      91             Ros  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a new user\n",
    "new_user_id = df['user_id'].max() + 1\n",
    "\n",
    "desired_attributes = {'light', 'sweet', 'citrus'}\n",
    "\n",
    "# Sort wines by points in descending order\n",
    "df_sorted = df.sort_values('points', ascending=False)\n",
    "\n",
    "# Filter wines based on desired attributes\n",
    "filtered_wines = df_sorted[df_sorted['tokens'].apply(lambda tokens: all(attribute in tokens for attribute in desired_attributes))]\n",
    "\n",
    "# Get the recommendations\n",
    "recommended_wines = hybrid_recommendations(new_user_id, desired_attributes)\n",
    "print(\"Number of wines with desired attribute(s):\", len(filtered_wines))\n",
    "print(\"Top 10 Recommendations for new user with Desired Attributes (Hybrid Approach):\")\n",
    "recommended_wines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created a personalised wine recommender using a hybrid approach:\n",
    "- compute the predicted ratings for all wines using SVD (collaborative filtering) \n",
    "- calculate the cosine similarities between the user's desired attributes and our wine tokens (content-based filtering)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm                         | RMSE     | Precision@k (%)| Recall@k (%)|\n",
    "|-----------------------------------|----------|:-----------:|:--------:|\n",
    "| Normal Predictor                  | 2.176 |   57.0  | 16.3 |\n",
    "| Baseline Predictor                | 1.614 |   72.4  | 9.6 |\n",
    "| KNN Basic                         | 1.632 |   59.9  | 19.8 |\n",
    "| KNN with Means                    | 1.632 |   57.5  | 19.2 |\n",
    "| KNN with Z-score                  | 1.632 |   58.9  | 19.9 |\n",
    "| KNN Baseline                      | 1.614 |   72.1  | 9.2 |\n",
    "| **SVD**                           | **1.615** | **73.8**|**6.6**|\n",
    "| SVD (tuned)                    | 1.615 |   72.7  | 8.8 |\n",
    "| Non-negative Matrix Factorization | 1.632 |   59.7  | 19.1 |\n",
    "| Co-Clustering                     | 1.632 |   57.3  | 18.5 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, SVD (before tuning) has the best overall performance for the wine recommender as it has the lowest RMSE and the highest Precision@k. At 74%, it is relatively high, meaning that users are more likely to receive recommendations that they will enjoy, thus increasing user satisfaction and trust in the recommendations. However, it has the lowest recall, suggesting that it may not be capturing all the relevant wines for a user within the top k recommendations, like NMF.\n",
    "\n",
    "Overall, as our aim is to prioritize the quality of recommendations (i.e., how well the predicted ratings match the actual ratings and the relevance of recommended items), SVD would do a good job for our wine recommender."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Limitations\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD algorithm, while providing the highest precision, has a low recall value. This indicates that it may not be capturing all relevant wines for the user, even though the top k recommendations are mostly accurate.\n",
    "\n",
    "Many of the algorithms have low recall values, which could be a sign that this approach may not be the best fit for this particular problem or dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Recommendations\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the recall@k without sacrificing precision, additional features or metadata about the wines (e.g., grape variety, region, or tasting notes) to enhance the recommendation algorithm could be explored. \n",
    "\n",
    "We can consider segmenting users based on their preferences or behaviors to tailor the recommendations more effectively. Personalized recommendations can lead to improved user satisfaction and better overall performance of the recommender system.\n",
    "\n",
    "Lastly, we can perform A/B testing with different algorithms or different configurations of the chosen algorithm to find the most effective solution for our users. This approach allows us to compare the performance of different algorithms in a controlled environment and make data-driven decisions about which algorithm to use."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "72a51f30bf8c483e1fc0abe989f81cc66824b206d24365642f1a7e7f70f5a428"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
